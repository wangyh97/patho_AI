import random
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
from torch.autograd import Variable
import torchvision.transforms.functional as VF
from torchvision import transforms

import sys, argparse, os, copy, itertools, glob, datetime
import pandas as pd
import numpy as np
from sklearn.utils import shuffle
from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_fscore_support
from sklearn.model_selection import StratifiedKFold
from sklearn.datasets import load_svmlight_file
from collections import OrderedDict
import time
import timm
import timm.optim
import timm.scheduler

'''
####################################
2023-5-11 train with resnet18 extracted features:
    read from new feature files, rewrite relative path due to difference between sh.file & py.file in path
####################################
2023-5-14 updated:
    a. 重构了train_ptres/train_tcga，加入--record参数，默认为False模式（参数寻找模式），若为True则为模型获得模式，并进行：
        i. 激活tensorboard，将文件储存在：f'run/lrwdT_{args.lr}_{args.weight_decay}_{args.Tmax}'文件夹，每次训练会获得一个events
        ii. 记录模型，模型保存在：f'weights/lrwdT_{args.lr}_{args.weight_decay}_{args.Tmax}'文件夹，获得：
            1) Best_score.pth
            2) Best_auc.pth
            3) Best_avg_auc.pth
    *** 改动在train_tcga同步
2023-5-15 updated:
    writer.add_scalar('val_loss',test_loss_bag,epoch)
2023-5-16 update:
    change the naming strategy of saved pth files
2023-6-20 update:
    rewrite the logic using args.record:
        - control recording activity using arg: record, whose mode should be one of [none,best,all]
            - none: only result files would be generated
            - best: training process will be recorded using tensorboard, only weights achieving best score/auc/avg_auc 
              throughout the training process will be recorded
            - all: training process will be recorded using tensorboard, all local best weights best score/auc/avg_auc
              will be recorded
        - introduce function train_epoch,recording & model_recorder
    TODO: 
        - new training file need to be tested
2023-6-23 update:
    remove arg:run, add arg:description
2023-7-18 update:
    new function: load_features -- use newly add args: scale/layer to control the features selected, do not need train_PtRes50.py anymore
    add arg: kfold: pass an int > 0 to activate k fold cross val
2023-7-21 update:
    add k fold judgement in func::load_features
    add arg::feature to func::get_bag_feats
'''

# load data

# =====>>>> current working dir is where the bash file located, not the executed py file <<<<==============

def load_features(scale,layer,K):
    features = np.load(f'../../../data/pretrained_resnet{layer}/{scale}X_full_slide_features_PtRes{layer}.npy',
                       allow_pickle=True).item()
    train = np.load(f'../../../config/data_segmentation_csv/{scale}X_tv_grouping.npy',allow_pickle=True).item()
    full = np.load(f'../../../config/data_segmentation_csv/{scale}X_full.npy', allow_pickle=True).item()
    full_index = list(full['full_list'].index)
    train_index = list(train['tv_list'].index)  #用于k折 train/val的数据的原始index
    test_index = list(set(full_index)-set(train_index)) #用于独立验证的test的数据的原始index

    train_list = []
    val_list = []
    if K != 0:
        X = train_index
        y = train['tv_list'].loc[train_index,'TMB_H/L'].tolist()
        sKF = StratifiedKFold(n_splits=K)
        for train_iloc,val_iloc in sKF.split(X,y):
            train_list.append([train_index[i] for i in train_iloc])
            val_list.append([train_index[i] for i in val_iloc])
    else:
        # 这里应该加载  config/data_segmentation_csv/{scale}X_grouping.npy 文件，获取train / val的分组
        pass

    index_dict = {ind: i for i, ind in enumerate(
        full_index)}  # feature dict -- index{i} is generated by iloc, meaning i is continuous index except the original uncontinuous ones, need transform using index read from grouping infos

    return features,train_list,val_list,test_index,index_dict # train / val_list存放的是k折train / val index列表，每个列表有k个小列表，小列表中存放当前折内用于train / val的图像的原始index

def load_PtSimclr_features(scale,load,K):
    features = np.load(f'../../../data/{load}/{scale}X_full_slide_features.npy',
                       allow_pickle=True).item()
    train = np.load(f'../../../config/data_segmentation_csv/{scale}X_tv_grouping.npy',allow_pickle=True).item()
    full = np.load(f'../../../config/data_segmentation_csv/{scale}X_full.npy', allow_pickle=True).item()
    full_index = list(full['full_list'].index)

    train_index = list(train['tv_list'].index)  # 用于k折 train/val的数据的原始index
    test_index = list(set(full_index)-set(train_index))  # 用于独立验证的test的数据的原始index

    train_list = []
    val_list = []
    if K != 0:
        X = train_index
        y = train['tv_list'].loc[train_index,'TMB_H/L'].tolist()
        sKF = StratifiedKFold(n_splits=K)
        for train_iloc,val_iloc in sKF.split(X,y):
            train_list.append([train_index[i] for i in train_iloc])
            val_list.append([train_index[i] for i in val_iloc])
    else:
        # 这里应该加载  config/data_segmentation_csv/{scale}X_grouping.npy 文件，获取train / val的分组
        pass

    index_dict = {ind: i for i, ind in enumerate(
        full_index)}  # feature dict -- index{i} is generated by iloc, meaning i is continuous index except the original uncontinuous ones, need transform using index read from grouping infos

    return features,train_list,val_list,test_index,index_dict # train / val_list存放的是k折train / val index列表，每个列表有k个小列表，小列表中存放当前折内用于train / val的图像的原始index

def set_seed(seed=10):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)  # 为了禁止hash随机化，使得实验可复现
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.
    print('seed set')
#     torch.backends.cudnn.benchmark = False
#     torch.backends.cudnn.deterministic = True

def feat_sampler(feats,target_num,mode):
    #对每个feat进行处理
    assert mode in ['simple','cluster'],'invalid mode'

    def simple_sample(feats,target_num):
        N = feats.shape[0]
        if N < target_num:
            pass # aug and upsample
        elif N > target_num:
            pass # downsample
        pass
    def cluster(feats,target_num):
        #modified from ReMix -- reduce.py
        feats = np.ascontiguousarray(feats, dtype=np.float32)
        kmeans = Kmeans(k=target_num, pca_dim=-1)
        kmeans.cluster(feats, seed=66)  # for reproducibility
        assignments = kmeans.labels.astype(np.int64)
        # compute the centroids for each cluster
        centroids = np.array([np.mean(feats[assignments == i], axis=0)
                              for i in range(args.num_prototypes)])

        # compute covariance matrix for each cluster
        covariance = np.array([np.cov(feats[assignments == i].T)
                               for i in range(args.num_prototypes)])
        # the semantic shift vectors are enough.
        semantic_shift_vectors = []
        for cov in covariance:
            semantic_shift_vectors.append(
                # sample shift vector from zero-mean multivariate Gaussian distritbuion N(0, cov)
                np.random.multivariate_normal(np.zeros(cov.shape[0]), cov,
                                              size=args.num_shift_vectors))

        semantic_shift_vectors = np.array(semantic_shift_vectors)
        del feats
        return centroids,semantic_shift_vectors

    def biased_sampling():
        pass
    

    if mode == 'simple':
        resampled_feats = simple_sample(feat,target_num)
        pass
    elif mode == 'cluster':
        maj_feats = cluster(feat)
        resampled_feats = simple_sample(maj_feats,target_num)
        pass

    return resampled_feats


def get_bag_feats(features,index,index_dict,args):
    label_dict = {'L': 0, 'H': 1}
    feats_og = pd.DataFrame(features[f'index{index_dict[index]}'][2])
    feats = shuffle(feats_og).reset_index(drop=True).to_numpy()

    if args.sample:
        feats = feat_sampler(feats)

    label_og = label_dict[features[f'index{index_dict[index]}'][1]]  # transformed label in form of int,[0,1]

    label = np.zeros(args.num_classes)
    if args.num_classes == 1:
        label[0] = label_og
    else:
        if int(label_og) <= (len(label) - 1):
            label[int(label_og)] = 1
    return label, feats


def train(features,train_index, milnet, criterion, optimizer, index_dict,args):
    milnet.train()
    train_index = shuffle(train_index)
    total_loss = 0
    bc = 0
    Tensor = torch.cuda.FloatTensor
    #     Tensor = torch.FloatTensor
    for i in range(len(train_index)):
        optimizer.zero_grad()
        label, feats = get_bag_feats(features,train_index[i],index_dict,args)
        feats = dropout_patches(feats, args.dropout_patch)
        bag_label = Variable(Tensor(np.array([label])))
        bag_feats = Variable(Tensor(np.array([feats])))
        bag_feats = bag_feats.view(-1, args.feats_size)
        ins_prediction, bag_prediction, _, _ = milnet(
            bag_feats)  # 使用多卡会出现多组bag prediciton，使计算bag loss时criterion时bag prediction / bag labelshape不匹配 -- 单卡多线程
        max_prediction, _ = torch.max(ins_prediction, 0)
        bag_loss = criterion(bag_prediction.view(1, -1), bag_label.view(1, -1))
        max_loss = criterion(max_prediction.view(1, -1), bag_label.view(1, -1))
        loss = 0.5 * bag_loss + 0.5 * max_loss
        l2_loss = 0
        if args.reg == True:
            for param in milnet.parameters():
                l2_loss += torch.norm(param)
        loss += args.reg_coef*l2_loss
        loss.backward()
        optimizer.step()
        total_loss = total_loss + loss.item()
    #         sys.stdout.write('\r Training bag [%d/%d] bag loss: %.4f' % (i, len(train_index), loss.item()))
    return total_loss / len(train_index)


def dropout_patches(feats, p):
    idx = np.random.choice(np.arange(feats.shape[0]), int(feats.shape[0] * (1 - p)), replace=False)
    sampled_feats = np.take(feats, idx, axis=0)
    pad_idx = np.random.choice(np.arange(sampled_feats.shape[0]), int(feats.shape[0] * p), replace=False)
    pad_feats = np.take(sampled_feats, pad_idx, axis=0)
    sampled_feats = np.concatenate((sampled_feats, pad_feats), axis=0)
    return sampled_feats


def test(features,test_df, milnet, criterion, index_dict,optimizer, args):
    milnet.eval()
    total_loss = 0
    test_labels = []
    test_predictions = []
    Tensor = torch.cuda.FloatTensor
    #     Tensor = torch.FloatTensor
    with torch.no_grad():
        for i in range(len(test_df)):
            label, feats = get_bag_feats(features,test_df[i], index_dict,args)
            bag_label = Variable(Tensor(np.array([label])))
            bag_feats = Variable(Tensor(np.array([feats])))
            bag_feats = bag_feats.view(-1, args.feats_size)
            ins_prediction, bag_prediction, _, _ = milnet(bag_feats)
            max_prediction, _ = torch.max(ins_prediction, 0)
            bag_prediction = torch.mean(bag_prediction, dim=0)
            bag_loss = criterion(bag_prediction.view(1, -1), bag_label.view(1, -1))
            max_loss = criterion(max_prediction.view(1, -1), bag_label.view(1, -1))
            loss = 0.5 * bag_loss + 0.5 * max_loss
            l2_loss = 0
            if args.reg == True:
                for param in milnet.parameters():
                    l2_loss += torch.norm(param)
            loss += args.reg_coef*l2_loss
            total_loss = total_loss + loss.item()
            sys.stdout.write('\r Testing bag [%d/%d] bag loss: %.4f' % (i, len(test_df), loss.item()))
            test_labels.extend([label])
            if args.average:
                test_predictions.extend([(0.5 * torch.sigmoid(max_prediction) + 0.5 * torch.sigmoid(
                    bag_prediction)).squeeze().cpu().numpy()])
            else:
                test_predictions.extend([(0.0 * torch.sigmoid(max_prediction) + 1.0 * torch.sigmoid(
                    bag_prediction)).squeeze().cpu().numpy()])
    test_labels = np.array(test_labels)
    test_predictions = np.array(test_predictions)
    auc_value, _, thresholds_optimal = multi_label_roc(test_labels, test_predictions, args.num_classes, pos_label=1)
    if args.num_classes == 1:
        class_prediction_bag = copy.deepcopy(test_predictions)
        class_prediction_bag[test_predictions >= thresholds_optimal[0]] = 1
        class_prediction_bag[test_predictions < thresholds_optimal[0]] = 0
        test_predictions = class_prediction_bag
        test_labels = np.squeeze(test_labels)
    else:
        for i in range(args.num_classes):
            class_prediction_bag = copy.deepcopy(test_predictions[:, i])
            class_prediction_bag[test_predictions[:, i] >= thresholds_optimal[i]] = 1
            class_prediction_bag[test_predictions[:, i] < thresholds_optimal[i]] = 0
            test_predictions[:, i] = class_prediction_bag
    bag_score = 0
    for i in range(0, len(test_df)):
        bag_score = np.array_equal(test_labels[i], test_predictions[i]) + bag_score
    avg_score = bag_score / len(test_df)

    return total_loss / len(test_df), avg_score, auc_value, thresholds_optimal


def multi_label_roc(labels, predictions, num_classes, pos_label=1):
    fprs = []
    tprs = []
    thresholds = []
    thresholds_optimal = []
    aucs = []
    if len(predictions.shape) == 1:
        predictions = predictions[:, None]
    for c in range(0, num_classes):
        label = labels[:, c]
        prediction = predictions[:, c]
        fpr, tpr, threshold = roc_curve(label, prediction, pos_label=1)
        fpr_optimal, tpr_optimal, threshold_optimal = optimal_thresh(fpr, tpr, threshold)
        c_auc = roc_auc_score(label, prediction)
        aucs.append(c_auc)
        thresholds.append(threshold)
        thresholds_optimal.append(threshold_optimal)
    return aucs, thresholds, thresholds_optimal

best_score = 0
best_auc = 0
best_avg_auc = 0
best_loss = 0
best_loss_score = 0
best_loss_auc = 0
best_loss_avg_auc = 0
best_loss_epoch = 0
def recording(record,net,saving_path,current_score,aucs,test_loss_bag,epoch,thresholds_optimal):
    global best_score
    global best_auc
    global best_avg_auc
    global best_loss
    global best_loss_score
    global best_loss_auc
    global best_loss_avg_auc
    global best_loss_epoch
    # return:
    def model_recorder(record,net,metrics,saving_path,epoch):
        # DONOT need model_recording when using K fold cross-validation，if needed, set arg:recording
        # arg::record only affect model saving, training curve will be recorded anyway
        # record should be ['none','best','all']
        # if record == none, weight will not be saved, else, weights will be saved with name generated by recorder every epoch after conditional judgement
        save_name = None
        if record == 'none':
            pass
        elif record == 'best':
            save_name = os.path.join(saving_path, f'{metrics}.pth')
        elif record == 'all':
            save_name = os.path.join(saving_path, str(epoch)+f'{metrics}.pth')
        if save_name:
            torch.save(net.state_dict(), save_name)

    # print infos with or w/o saving models
    if current_score >= best_score:
        best_score = current_score
        print('Best_score thresholds ===>>> ' + '|'.join(
            'class-{}>>{}'.format(*k) for k in enumerate(thresholds_optimal)))
        model_recorder(record,net,'best_score',saving_path,epoch)

    if aucs[1] >= best_auc:
        best_auc = aucs[1]
        print('Best_auc thresholds ===>>> ' + '|'.join(
            'class-{}>>{}'.format(*k) for k in enumerate(thresholds_optimal)))
        print(f'Best auc ===>>>{best_auc}')
        model_recorder(record, net,'best_auc', saving_path, epoch)

#     if sum(aucs) >= best_avg_auc:
#         best_avg_auc = sum(aucs)
#         print('Best_avg_auc thresholds ===>>> ' + '|'.join(
#             'class-{}>>{}'.format(*k) for k in enumerate(thresholds_optimal)))
#         print('best avg_auc ===>>>' + '|'.join('class-{}>>{}'.format(*k) for k in enumerate(aucs)))
#         model_recorder(record, net, 'best_avg_auc', saving_path, epoch)

    if best_loss == 0:
        best_loss = test_loss_bag
    if test_loss_bag < best_loss:
        best_loss = test_loss_bag
        best_loss_score = current_score
        best_loss_auc = aucs[1]
        best_loss_epoch = epoch
        model_recorder(record, net, 'best_loss', saving_path, epoch)
    return best_score,best_auc,best_avg_auc,best_loss_epoch,best_loss_score,best_loss_auc,best_loss

def train_epoch(k,features,index_dict,train_index,val_index,real_test_index,milnet,criterion,optimizer,args,scheduler):
    writer = SummaryWriter(f'run/lrwdT_{args.lr}_{args.weight_decay}_{args.Tmax}/fold{k}')  # path saving tensorboard logdir
    if args.record != 'none':   
        save_path = os.path.join('weights', f'lrwdT_{args.lr}_{args.weight_decay}_{args.Tmax}/fold{k}')  # path saving models
        os.makedirs(save_path, exist_ok=True)
    else:
        save_path = ''

    for epoch in range(1, args.num_epochs):
        train_index = shuffle(train_index)
        val_index = shuffle(val_index)

        train_loss_bag = train(features,train_index, milnet, criterion, optimizer,index_dict, args)  # iterate all bags
        test_loss_bag, avg_score, aucs, thresholds_optimal = test(features,val_index, milnet, criterion,index_dict, optimizer, args)
        
        if epoch%5 ==0 or epoch <10:
            real_test_loss_bag, test_avg_score, test_aucs,_ = test(features,real_test_index, milnet, criterion,index_dict, optimizer, args)
        print('\r Epoch [%d/%d] train loss: %.4f test loss: %.4f, average score: %.4f, AUC: ' %
              (epoch, args.num_epochs, train_loss_bag, test_loss_bag, avg_score) + '|'.join(
            'class-{}>>{}'.format(*k) for k in enumerate(aucs)))
        if args.warmup:
            scheduler.step(epoch)
        else:
            scheduler.step()
        current_score = (sum(aucs) + avg_score) / 2  # 均衡考虑auc与accuracy
        
        #training curve will be recorded anyway
        writer.add_scalar('train_loss', train_loss_bag, epoch)
        writer.add_scalar('val_loss', test_loss_bag, epoch)
        writer.add_scalar('avg_score', avg_score, epoch)
        writer.add_scalar('class 0 aucs', aucs[0], epoch)
        writer.add_scalar('class_1 aucs', aucs[1], epoch)
        
        writer.add_scalar('test_loss', real_test_loss_bag, epoch)
        writer.add_scalar('test_avg_score', test_avg_score, epoch)
        writer.add_scalar('test_class_1 aucs', test_aucs[1], epoch)

        best_score, best_auc, best_avg_auc, best_loss_epoch, best_loss_score, best_loss_auc, best_loss= recording(
        args.record, milnet, save_path, current_score, aucs, test_loss_bag, epoch, thresholds_optimal)

    return best_score, best_auc, best_avg_auc, best_loss_epoch, best_loss_score, best_loss_auc, best_loss
def optimal_thresh(fpr, tpr, thresholds, p=0):
    loss = (fpr - tpr) - p * tpr / (fpr + tpr + 1)
    idx = np.argmin(loss, axis=0)
    return fpr[idx], tpr[idx], thresholds[idx]

# def load_model(args):
#     if args.model == 'dsmil':
#         import dsmil as mil
#     elif args.model == 'abmil':
#         import abmil as mil

#     i_classifier = mil.FCLayer(in_size=args.feats_size, out_size=args.num_classes).cuda()
#     b_classifier = mil.BClassifier(input_size=args.feats_size, output_class=args.num_classes,
#                                    dropout_v=args.dropout_node, nonlinear=args.non_linearity).cuda()
#     milnet = mil.MILNet(i_classifier, b_classifier).cuda()

#     milnet = torch.nn.DataParallel(milnet)
#     milnet = milnet.cuda()

#     if args.model == 'dsmil':
#         state_dict_weights = torch.load('../init.pth')
#         try:
#             milnet.load_state_dict(state_dict_weights, strict=False)
#         except:
#             del state_dict_weights['b_classifier.v.1.weight']
#             del state_dict_weights['b_classifier.v.1.bias']
#             milnet.load_state_dict(state_dict_weights, strict=False)
#     return milnet

def reload_model(args):
    if args.model == 'dsmil':
        import dsmil as mil
    elif args.model == 'abmil':
        import abmil as mil
    
    if args.load == 'none':
        weight = torch.load('../new_init_512.pth')
    else:
        weight = torch.load('../new_init_256.pth')

    i_classifier = mil.FCLayer(in_size=args.feats_size, out_size=args.num_classes).cuda()
    b_classifier = mil.BClassifier(input_size=args.feats_size, output_class=args.num_classes,
                                   dropout_v=args.dropout_node, nonlinear=args.non_linearity).cuda()
    milnet = mil.MILNet(i_classifier, b_classifier).cuda()
    milnet = torch.nn.DataParallel(milnet)
    milnet = milnet.cuda()
    milnet.load_state_dict(weight,strict=True)
    return milnet

def main():
    parser = argparse.ArgumentParser(description='Train DSMIL on 20x patch features learned by SimCLR')
    # to finetune
    parser.add_argument('--lr', default=0.0002, type=float, help='Initial learning rate [0.0002]')
    parser.add_argument('--weight_decay', default=5e-3, type=float, help='Weight decay [5e-3]')
    parser.add_argument('--Tmax', default=50, type=int, help='Tmax used in CosineAnnealingLR,choose from [200,100,50]')
    
    # select features
    parser.add_argument('--scale',type=int,help='select magnificant scale of the extracted patches,select form [10,20]')
    parser.add_argument('--layer',type=int,help='select resnet18/50 as feature extractor,[18]')
    parser.add_argument('--load',type=str,default='none',help='select pretrained embedder,[none,TCGA_high,TCGA_low,c16_high]')
    
    #to explore
    parser.add_argument('--reg',type=bool,default=False,help='add extra l2 regularization to loss [False]')
    parser.add_argument('--reg_coef',type=float,default=0,help='regularization coeffcient added to the punishment')
    parser.add_argument('--warmup',type=bool,default=False,help='add warmup to cosineannealing scheduler')
    parser.add_argument('--sample',type=bool,default=False,help='whether feats be balanced before training, see func<feats_sampler>, default target number is 100')
    
    # fixed args
    parser.add_argument('--num_classes', default=2, type=int, help='Number of output classes [2]')
    parser.add_argument('--feats_size', default=512, type=int, help='Dimension of the feature size [512]')
    parser.add_argument('--num_epochs', default=100, type=int, help='Number of total training epochs [40|200]')
    parser.add_argument('--gpu_index', type=str, help='GPU ID(s) [0]')
    parser.add_argument('--model', default='dsmil', type=str, help='MIL model [dsmil]')
    parser.add_argument('--dropout_patch', default=0, type=float, help='Patch dropout rate [0]')
    parser.add_argument('--dropout_node', default=0, type=float, help='Bag classifier dropout rate [0]')
    parser.add_argument('--non_linearity', default=1, type=float, help='Additional nonlinear operation [0]')
    parser.add_argument('--average', type=bool, default=True,
                        help='Average the score of max-pooling and bag aggregating')
    parser.add_argument('--description', type=str,
                        help='short description for the trial, saving results in file: results_{description}.txt')
    parser.add_argument('--record', type=str, default='best',
                        help='activate tensorboard and record, save the best model, result file will be generated anyway,choose from [best,all,none][best]')
    parser.add_argument('--kfold',type=int,default=0,help='use k fold cross val')
    args = parser.parse_args()
    #     gpu_ids = args.gpu_index
    os.environ['CUDA_VISIBLE_DEVICES'] = str(args.gpu_index)
    set_seed()

    # load data
    if args.load == 'none':
        features,train_list,val_list,test_index,index_dict = load_features(args.scale,args.layer,args.kfold)
    elif args.load in ['TCGA_high','TCGA_low','c16_high']:
        features, train_list, val_list, test_index, index_dict = load_PtSimclr_features(args.scale, args.load, args.kfold)
    else:
        print('invalid load mode')
    # saving results during each epoch
    metrics = {
        'score' : [],
        'auc' : [],
        'best_epoch': [],
        'loss_score':[],
        'loss_auc':[],
        'loss':[]
    }

    for i in range(len(train_list)):
        #重载模型、criterion、optimizer、scheduler
        milnet = reload_model(args)
        criterion = nn.BCEWithLogitsLoss()
        optimizer = torch.optim.Adam(milnet.parameters(), lr=args.lr, betas=(0.5, 0.9), weight_decay=args.weight_decay)
        if args.warmup:
            scheduler = timm.scheduler.CosineLRScheduler(optimizer,args.Tmax,lr_min=1e-8,warmup_t=args.Tmax//10,warmup_lr_init=1e-7)
        else:
            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, args.Tmax, 0.000005)
            
        print(milnet.state_dict())
        print(f'fold:{i+1}')
        sc,auc,_,best_ep,loss_sc,loss_auc,best_ls= train_epoch(i,features,index_dict,train_list[i],val_list[i],test_index,milnet,criterion,optimizer,args,scheduler)

        metrics['score'].append(sc)
        metrics['auc'].append(auc)
        metrics['best_epoch'].append(best_ep)
        metrics['loss_score'].append(loss_sc)
        metrics['loss_auc'].append(loss_auc)
        metrics['loss'].append(best_ls)
        print(f'fold{i+1} finished')
        
    avg_score = np.mean(metrics['score'])
    avg_auc = np.mean(metrics['auc'])
    avg_best_epoch = np.mean(metrics['best_epoch'])
    avg_loss_score = np.mean(metrics['loss_score'])
    avg_loss_auc = np.mean(metrics['loss_auc'])
    avg_loss = np.mean(metrics['loss'])
    with open(f'results_{args.description}.txt', 'a+') as f:
        f.write(
            f'{args.lr},{args.weight_decay},{args.Tmax},{avg_score},{avg_auc},{avg_best_epoch},{avg_loss_score},{avg_loss_auc},{avg_loss}\n')


if __name__ == '__main__':
    tick = time.time()
    main()
    print(time.time() - tick)

# saved form:(args.lr,args.weight_decay,args.Tmax,best_score,best_auc,best_avg_auc,best_loss_epoch,best_loss_score,best_loss_auc,best_loss_avg_auc)
