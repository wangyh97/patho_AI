{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "785315d0-94eb-47f1-a067-231928da8d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms.functional as VF\n",
    "from torchvision import transforms\n",
    "\n",
    "import sys, argparse, os, copy, itertools, glob, datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_fscore_support,confusion_matrix\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from collections import OrderedDict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2a643b4-09f3-4db4-bb98-f3457990e9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.load('../../data/pretrained_resnet18/10X_full_slide_features_PtRes18.npy',allow_pickle=True).item()\n",
    "full = np.load('../../config/data_segmentation_csv/10X_full.npy',allow_pickle=True).item()\n",
    "full_index = list(full['full_list'].index)\n",
    "grouping = np.load('../../config/data_segmentation_csv/10X_grouping.npy',allow_pickle=True).item()\n",
    "test_index = grouping['test_list'].index\n",
    "\n",
    "index_dict = {ind:i for i,ind in enumerate(full_index)}\n",
    "label_dict = {'L':0,'H':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d20a6bb7-e1b3-452d-afb1-c440d0cf576b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class args():\n",
    "    def __init__(self):\n",
    "        self.dataset = 'TCGA_BLCA'\n",
    "        self.num_classes = 2\n",
    "        self.feats_size = 512\n",
    "        self.average = False\n",
    "        self.dropout_node = 0\n",
    "        self.non_linearity = 1\n",
    "        self.path = './hyperparam_select_batch_9/weights/lrwdT_0.00046_1.9e-06_50/163best_auc.pth'\n",
    "\n",
    "    def __getattribute__(self, __name: str):\n",
    "        return object.__getattribute__(self, __name)\n",
    "    \n",
    "args = args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "344c662b-d19c-42b9-8df8-9bc5886932b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed set\n"
     ]
    }
   ],
   "source": [
    "def get_bag_feats(index, args):\n",
    "    global features\n",
    "    global index_dict\n",
    "    \n",
    "    feats_og = pd.DataFrame(features[f'index{index_dict[index]}'][2])\n",
    "    feats = shuffle(feats_og).reset_index(drop=True).to_numpy()\n",
    "    label_og = label_dict[features[f'index{index_dict[index]}'][1]]   # transformed label in form of int,[0,1]\n",
    "    \n",
    "    label = np.zeros(args.num_classes)\n",
    "    if args.num_classes==1:\n",
    "        label[0] = label_og\n",
    "    else:\n",
    "        if int(label_og)<=(len(label)-1):\n",
    "            label[int(label_og)] = 1\n",
    "    return label,feats\n",
    "'''\n",
    "example of label/feature : get_bag_feats(test_index[2],args)\n",
    "label:[1. 0.]\n",
    "feature:[[2.5330880e+00 1.6554745e-01 8.0470458e-02 ... 1.3655423e+00\n",
    "  5.7236932e-02 5.2817654e-02]\n",
    " [2.8611205e+00 2.9038048e-01 6.0187571e-02 ... 1.8358935e+00\n",
    "  5.3482568e-01 6.2871813e-03]\n",
    " [3.3081994e+00 7.3715396e-02 1.2616467e+00 ... 1.9259404e+00\n",
    "  1.4681002e-01 2.8594225e-03]\n",
    " ...\n",
    " [2.9693909e+00 3.2868910e-01 1.3055435e-01 ... 2.4260533e+00\n",
    "  1.7651926e-01 1.2930447e-01]\n",
    " [2.8800142e+00 3.0109720e-02 8.2876140e-01 ... 2.4528553e+00\n",
    "  5.6700967e-03 0.0000000e+00]\n",
    " [1.4685658e+00 1.6393182e-01 6.0487707e-04 ... 1.2453270e+00\n",
    "  0.0000000e+00 4.1464632e-03]]\n",
    "'''\n",
    "def set_seed(seed=10):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed) # 为了禁止hash随机化，使得实验可复现\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
    "    print('seed set')\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ee6995-5a3a-4ac3-a5d7-ccebd58323bf",
   "metadata": {},
   "source": [
    "# eval -- test（func）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "caa0347a-4c46-4121-bf6d-03bc711220da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_label_roc(labels, predictions, num_classes, pos_label=1):\n",
    "    fprs = []\n",
    "    tprs = []\n",
    "    thresholds = []\n",
    "    thresholds_optimal = []\n",
    "    aucs = []\n",
    "    if len(predictions.shape)==1:\n",
    "        predictions = predictions[:, None]\n",
    "    for c in range(0, num_classes):\n",
    "        label = labels[:, c]\n",
    "        prediction = predictions[:, c]\n",
    "        fpr, tpr, threshold = roc_curve(label, prediction, pos_label=1)\n",
    "        fpr_optimal, tpr_optimal, threshold_optimal = optimal_thresh(fpr, tpr, threshold)\n",
    "        c_auc = roc_auc_score(label, prediction)\n",
    "        aucs.append(c_auc)\n",
    "        thresholds.append(threshold)\n",
    "        thresholds_optimal.append(threshold_optimal)\n",
    "    return aucs, thresholds, thresholds_optimal\n",
    "\n",
    "def optimal_thresh(fpr, tpr, thresholds, p=0):\n",
    "    loss = (fpr - tpr) - p * tpr / (fpr + tpr + 1)\n",
    "    idx = np.argmin(loss, axis=0)\n",
    "    return fpr[idx], tpr[idx], thresholds[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "09976fad-5a9f-4e0b-81db-5e13f2b242dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_value:[0.5461538461538462, 0.5435897435897437],threshold_optimal:[0.9966737, 0.0010418614]first 5 class_pred_bag:[1. 0. 0. 1. 0.],first 5 test_pred:[[0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]],first 5 labels:[[0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]first 5 single char labels:[1, 0, 0, 0, 0],first 5 single char pred:[1, 0, 0, 1, 0]accuracy:0.4383561643835616"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "demo of values of intermediate variables:\n",
    "\n",
    "original label:tensor([[0., 1.]], device='cuda:0'),shape of feats:torch.Size([1, 53, 512])\n",
    "shape of feats after view:torch.Size([53, 512])\n",
    "shape of ins_pred:torch.Size([53, 2]),original bag_pred:tensor([[-2.9899,  2.7934],\n",
    "        [-3.7077,  3.5751],\n",
    "        [-3.6781,  3.7495],\n",
    "        [-3.8786,  3.5615]], device='cuda:0'),shape of original bag_pred:torch.Size([4, 2])\n",
    "max pred:tensor([ 0.9809, -2.4702], device='cuda:0'),bag pred after mean:tensor([-3.5636,  3.4199], device='cuda:0')\n",
    " Testing bag [0/73] bag loss: 0.9777 \n",
    "test laels:[0. 1.],test prediction : [array([0.02755601, 0.9683193 ], dtype=float32)]\n",
    "first 5 class_pred_bag:[1. 0. 0. 0. 0.],\n",
    "first 5 test_pred:[[0. 1.]\n",
    " [0. 0.]\n",
    " [1. 0.]\n",
    " [1. 0.]\n",
    " [1. 0.]],\n",
    " first 5 labels:[[0. 1.]\n",
    " [1. 0.]\n",
    " [1. 0.]\n",
    " [1. 0.]\n",
    " [1. 0.]]\n",
    " first 5 single char labels:[1, 0, 0, 0, 0],first 5 single char pred:[1, 0, 0, 1, 0]\n",
    "'''\n",
    "#load net\n",
    "import dsmil\n",
    "i_classifier = dsmil.FCLayer(in_size=args.feats_size, out_size=args.num_classes).cuda()\n",
    "b_classifier = dsmil.BClassifier(input_size=args.feats_size, output_class=args.num_classes, dropout_v=args.dropout_node, nonlinear=args.non_linearity).cuda()\n",
    "milnet = dsmil.MILNet(i_classifier, b_classifier).cuda()\n",
    "milnet = torch.nn.DataParallel(milnet)  #若开启dataparallel，计算得到4个bag pred，使用torch.mean得到最终的bag pred\n",
    "milnet = milnet.cuda()\n",
    "#load params\n",
    "state_dict_weights = torch.load(args.path)\n",
    "try:\n",
    "    milnet.load_state_dict(state_dict_weights, strict=False)\n",
    "except:\n",
    "    del state_dict_weights['b_classifier.v.1.weight']\n",
    "    del state_dict_weights['b_classifier.v.1.bias']\n",
    "    milnet.load_state_dict(state_dict_weights, strict=False)\n",
    "\n",
    "test_df = test_index\n",
    "criterion = criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "milnet.eval()\n",
    "total_loss = 0\n",
    "test_labels = []\n",
    "test_predictions = []\n",
    "Tensor = torch.cuda.FloatTensor\n",
    "#     Tensor = torch.FloatTensor\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_df)):\n",
    "        label, feats = get_bag_feats(test_df[i], args)\n",
    "        bag_label = Variable(Tensor([label]))\n",
    "        bag_feats = Variable(Tensor([feats]))\n",
    "        bag_feats = bag_feats.view(-1, args.feats_size)\n",
    "        ins_prediction, bag_prediction, _, _ = milnet(bag_feats)\n",
    "        max_prediction, _ = torch.max(ins_prediction, 0)  \n",
    "        bag_prediction = torch.mean(bag_prediction,dim=0)\n",
    "        bag_loss = criterion(bag_prediction.view(1, -1), bag_label.view(1, -1))\n",
    "        max_loss = criterion(max_prediction.view(1, -1), bag_label.view(1, -1))\n",
    "        loss = 0.5*bag_loss + 0.5*max_loss\n",
    "        total_loss = total_loss + loss.item()\n",
    "        test_labels.extend([label])\n",
    "        #test predictions equals to sigmoid（bag prediction）\n",
    "        if args.average:\n",
    "            test_predictions.extend([(0.5*torch.sigmoid(max_prediction)+0.5*torch.sigmoid(bag_prediction)).squeeze().cpu().numpy()])\n",
    "        else: test_predictions.extend([(0.0*torch.sigmoid(max_prediction)+1.0*torch.sigmoid(bag_prediction)).squeeze().cpu().numpy()])\n",
    "test_labels = np.array(test_labels)\n",
    "test_predictions = np.array(test_predictions)\n",
    "auc_value, _, thresholds_optimal = multi_label_roc(test_labels, test_predictions, args.num_classes, pos_label=1)\n",
    "sys.stdout.write(f'auc_value:{auc_value},threshold_optimal:{thresholds_optimal}')\n",
    "if args.num_classes==1:\n",
    "    class_prediction_bag = copy.deepcopy(test_predictions)\n",
    "    class_prediction_bag[test_predictions>=thresholds_optimal[0]] = 1\n",
    "    class_prediction_bag[test_predictions<thresholds_optimal[0]] = 0\n",
    "    test_predictions = class_prediction_bag\n",
    "    test_labels = np.squeeze(test_labels)\n",
    "else:        \n",
    "    for i in range(args.num_classes):\n",
    "        class_prediction_bag = copy.deepcopy(test_predictions[:, i])\n",
    "        class_prediction_bag[test_predictions[:, i]>=thresholds_optimal[i]] = 1\n",
    "        class_prediction_bag[test_predictions[:, i]<thresholds_optimal[i]] = 0\n",
    "        test_predictions[:, i] = class_prediction_bag\n",
    "\n",
    "one_hot_labels = [np.argmax(i) for i in test_labels]\n",
    "one_hot_preds = [np.argmax(i) for i in test_predictions]\n",
    "c = confusion_matrix(one_hot_labels,one_hot_preds).ravel()\n",
    "tn, fp, fn, tp = c.ravel() #展平\n",
    "bag_score = 0\n",
    "for i in range(0, len(test_df)):\n",
    "    bag_score = np.array_equal(test_labels[i], test_predictions[i]) + bag_score       \n",
    "avg_score = bag_score / len(test_df)\n",
    "sys.stdout.write(f'accuracy:{avg_score}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72eb47f-2147-408a-9966-867971bba292",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writter = SummaryWriter('test/abc')\n",
    "writter.add_scalar('test',torch.tensor([0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce833fc8-b020-4f5b-802a-5f8be1ef8585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def file_remover(folder):\n",
    "    files = os.listdir(f'./hyperparam_select_batch_9/weights/{folder}')\n",
    "    #change working path\n",
    "    os.chdir(f'./hyperparam_select_batch_9/weights/{folder}')\n",
    "    best_score = []\n",
    "    best_auc = []\n",
    "    best_avg_auc = []\n",
    "\n",
    "    for name in files:\n",
    "        first_num = int(name.split('b')[0])\n",
    "        if 'avg' in name:\n",
    "            best_avg_auc.append(first_num) \n",
    "        elif 'score' in name:\n",
    "            best_score.append(first_num)\n",
    "        elif 'auc' in name:\n",
    "            best_auc.append(first_num)\n",
    "    max_score = max(best_score)  \n",
    "    max_auc = max(best_auc)\n",
    "    max_avg_auc = max(best_avg_auc)\n",
    "#     print(os.getcwd())\n",
    "#     print(f'{max_score}best_score.pth')  \n",
    "#     print(f'{max_auc}best_auc.pth')\n",
    "#     print(f'{max_avg_auc}best_avg_auc.pth')\n",
    "    \n",
    "    #remove files that not satisfy the best\n",
    "    for name in files:\n",
    "        if name not in [f'{max_score}best_score.pth',f'{max_auc}best_auc.pth',f'{max_avg_auc}best_avg_auc.pth']:\n",
    "            os.remove(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "294c2b9a-b1bf-40bd-bcaf-9a2121179f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88best_score.pth\n",
      "88best_auc.pth\n",
      "79best_avg_auc.pth\n",
      "101best_score.pth\n",
      "101best_auc.pth\n",
      "101best_avg_auc.pth\n",
      "163best_score.pth\n",
      "163best_auc.pth\n",
      "163best_avg_auc.pth\n",
      "108best_score.pth\n",
      "108best_auc.pth\n",
      "108best_avg_auc.pth\n",
      "73best_score.pth\n",
      "75best_auc.pth\n",
      "75best_avg_auc.pth\n",
      "79best_score.pth\n",
      "79best_auc.pth\n",
      "79best_avg_auc.pth\n",
      "30best_score.pth\n",
      "30best_auc.pth\n",
      "30best_avg_auc.pth\n",
      "85best_score.pth\n",
      "85best_auc.pth\n",
      "85best_avg_auc.pth\n",
      "93best_score.pth\n",
      "30best_auc.pth\n",
      "26best_avg_auc.pth\n",
      "163best_score.pth\n",
      "163best_auc.pth\n",
      "163best_avg_auc.pth\n"
     ]
    }
   ],
   "source": [
    "#initialize path\n",
    "os.chdir(f'/home/wangyh/uro_biomarker/patho_AI/processing/mil classifier')\n",
    "folder_ls = os.listdir('./hyperparam_select_batch_9/weights/')\n",
    "\n",
    "for folder in folder_ls:\n",
    "    file_remover(folder)\n",
    "    #reset path\n",
    "    os.chdir(f'/home/wangyh/uro_biomarker/patho_AI/processing/mil classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412470f2-7709-4bf8-be8f-266c34de204e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patho_AI",
   "language": "python",
   "name": "patho_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
