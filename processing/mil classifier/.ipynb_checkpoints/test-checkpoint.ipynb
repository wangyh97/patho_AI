{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "785315d0-94eb-47f1-a067-231928da8d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms.functional as VF\n",
    "from torchvision import transforms\n",
    "\n",
    "import sys, argparse, os, copy, itertools, glob, datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_fscore_support,confusion_matrix\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from collections import OrderedDict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f2a643b4-09f3-4db4-bb98-f3457990e9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.load('../../data/pretrained_resnet18/10X_full_slide_features_PtRes18.npy',allow_pickle=True).item()\n",
    "full = np.load('../../config/data_segmentation_csv/10X_full.npy',allow_pickle=True).item()\n",
    "full_index = list(full['full_list'].index)\n",
    "grouping = np.load('../../config/data_segmentation_csv/10X_grouping.npy',allow_pickle=True).item()\n",
    "test_index = grouping['test_list'].index\n",
    "\n",
    "index_dict = {ind:i for i,ind in enumerate(full_index)}\n",
    "label_dict = {'L':0,'H':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d20a6bb7-e1b3-452d-afb1-c440d0cf576b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class args():\n",
    "    def __init__(self):\n",
    "        self.dataset = 'TCGA_BLCA'\n",
    "        self.num_classes = 2\n",
    "        self.feats_size = 512\n",
    "        self.average = False\n",
    "        self.dropout_node = 0\n",
    "        self.non_linearity = 1\n",
    "        self.path = './hyperparam_select_batch_9/weights/lrwdT_0.00044_6.4000000000000006e-06_50/85best_score.pth'\n",
    "        self.lr = 0.28\n",
    "        self.weight_decay = 1e-6\n",
    "\n",
    "    def __getattribute__(self, __name: str):\n",
    "        return object.__getattribute__(self, __name)\n",
    "    \n",
    "args = args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "344c662b-d19c-42b9-8df8-9bc5886932b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed set\n"
     ]
    }
   ],
   "source": [
    "def get_bag_feats(index, args):\n",
    "    global features\n",
    "    global index_dict\n",
    "    \n",
    "    feats_og = pd.DataFrame(features[f'index{index_dict[index]}'][2])\n",
    "    feats = shuffle(feats_og).reset_index(drop=True).to_numpy()\n",
    "    label_og = label_dict[features[f'index{index_dict[index]}'][1]]   # transformed label in form of int,[0,1]\n",
    "    \n",
    "    label = np.zeros(args.num_classes)\n",
    "    if args.num_classes==1:\n",
    "        label[0] = label_og\n",
    "    else:\n",
    "        if int(label_og)<=(len(label)-1):\n",
    "            label[int(label_og)] = 1\n",
    "    return label,feats\n",
    "'''\n",
    "example of label/feature : get_bag_feats(test_index[2],args)\n",
    "label:[1. 0.]\n",
    "feature:[[2.5330880e+00 1.6554745e-01 8.0470458e-02 ... 1.3655423e+00\n",
    "  5.7236932e-02 5.2817654e-02]\n",
    " [2.8611205e+00 2.9038048e-01 6.0187571e-02 ... 1.8358935e+00\n",
    "  5.3482568e-01 6.2871813e-03]\n",
    " [3.3081994e+00 7.3715396e-02 1.2616467e+00 ... 1.9259404e+00\n",
    "  1.4681002e-01 2.8594225e-03]\n",
    " ...\n",
    " [2.9693909e+00 3.2868910e-01 1.3055435e-01 ... 2.4260533e+00\n",
    "  1.7651926e-01 1.2930447e-01]\n",
    " [2.8800142e+00 3.0109720e-02 8.2876140e-01 ... 2.4528553e+00\n",
    "  5.6700967e-03 0.0000000e+00]\n",
    " [1.4685658e+00 1.6393182e-01 6.0487707e-04 ... 1.2453270e+00\n",
    "  0.0000000e+00 4.1464632e-03]]\n",
    "'''\n",
    "def set_seed(seed=10):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed) # 为了禁止hash随机化，使得实验可复现\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
    "    print('seed set')\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ee6995-5a3a-4ac3-a5d7-ccebd58323bf",
   "metadata": {},
   "source": [
    "# eval -- test（func）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "caa0347a-4c46-4121-bf6d-03bc711220da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_label_roc(labels, predictions, num_classes, pos_label=1):\n",
    "    fprs = []\n",
    "    tprs = []\n",
    "    thresholds = []\n",
    "    thresholds_optimal = []\n",
    "    aucs = []\n",
    "    if len(predictions.shape)==1:\n",
    "        predictions = predictions[:, None]\n",
    "    for c in range(0, num_classes):\n",
    "        label = labels[:, c]\n",
    "        prediction = predictions[:, c]\n",
    "        fpr, tpr, threshold = roc_curve(label, prediction, pos_label=1)\n",
    "        fpr_optimal, tpr_optimal, threshold_optimal = optimal_thresh(fpr, tpr, threshold)\n",
    "        c_auc = roc_auc_score(label, prediction)\n",
    "        aucs.append(c_auc)\n",
    "        thresholds.append(threshold)\n",
    "        thresholds_optimal.append(threshold_optimal)\n",
    "    return aucs, thresholds, thresholds_optimal\n",
    "\n",
    "def optimal_thresh(fpr, tpr, thresholds, p=0):\n",
    "    loss = (fpr - tpr) - p * tpr / (fpr + tpr + 1)\n",
    "    idx = np.argmin(loss, axis=0)\n",
    "    return fpr[idx], tpr[idx], thresholds[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "09976fad-5a9f-4e0b-81db-5e13f2b242dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_value:[0.6512820512820513, 0.6487179487179487],threshold_optimal:[0.6584029, 0.34987283]first 5 class_pred_bag:[1. 0. 0. 0. 0.],first 5 test_pred:[[0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]],first 5 labels:[[0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]"
     ]
    }
   ],
   "source": [
    "'''\n",
    "demo of values of intermediate variables:\n",
    "\n",
    "original label:tensor([[0., 1.]], device='cuda:0'),shape of feats:torch.Size([1, 53, 512])\n",
    "shape of feats after view:torch.Size([53, 512])\n",
    "shape of ins_pred:torch.Size([53, 2]),original bag_pred:tensor([[-2.9899,  2.7934],\n",
    "        [-3.7077,  3.5751],\n",
    "        [-3.6781,  3.7495],\n",
    "        [-3.8786,  3.5615]], device='cuda:0'),shape of original bag_pred:torch.Size([4, 2])\n",
    "max pred:tensor([ 0.9809, -2.4702], device='cuda:0'),bag pred after mean:tensor([-3.5636,  3.4199], device='cuda:0')\n",
    " Testing bag [0/73] bag loss: 0.9777 \n",
    "test laels:[0. 1.],test prediction : [array([0.02755601, 0.9683193 ], dtype=float32)]\n",
    "first 5 class_pred_bag:[1. 0. 0. 0. 0.],\n",
    "first 5 test_pred:[[0. 1.]\n",
    " [0. 0.]\n",
    " [1. 0.]\n",
    " [1. 0.]\n",
    " [1. 0.]],\n",
    " first 5 labels:[[0. 1.]\n",
    " [1. 0.]\n",
    " [1. 0.]\n",
    " [1. 0.]\n",
    " [1. 0.]]\n",
    "'''\n",
    "#load net\n",
    "import dsmil\n",
    "i_classifier = dsmil.FCLayer(in_size=args.feats_size, out_size=args.num_classes).cuda()\n",
    "b_classifier = dsmil.BClassifier(input_size=args.feats_size, output_class=args.num_classes, dropout_v=args.dropout_node, nonlinear=args.non_linearity).cuda()\n",
    "milnet = dsmil.MILNet(i_classifier, b_classifier).cuda()\n",
    "milnet = torch.nn.DataParallel(milnet)  #若开启dataparallel，计算得到4个bag pred，使用torch.mean得到最终的bag pred\n",
    "milnet = milnet.cuda()\n",
    "#load params\n",
    "state_dict_weights = torch.load(args.path)\n",
    "try:\n",
    "    milnet.load_state_dict(state_dict_weights, strict=False)\n",
    "except:\n",
    "    del state_dict_weights['b_classifier.v.1.weight']\n",
    "    del state_dict_weights['b_classifier.v.1.bias']\n",
    "    milnet.load_state_dict(state_dict_weights, strict=False)\n",
    "\n",
    "test_df = test_index\n",
    "criterion = criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optimizer = torch.optim.Adam(milnet.parameters(), lr=args.lr, betas=(0.5, 0.9), weight_decay=args.weight_decay)\n",
    "\n",
    "milnet.eval()\n",
    "total_loss = 0\n",
    "test_labels = []\n",
    "test_predictions = []\n",
    "Tensor = torch.cuda.FloatTensor\n",
    "#     Tensor = torch.FloatTensor\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_df)):\n",
    "        label, feats = get_bag_feats(test_df[i], args)\n",
    "        bag_label = Variable(Tensor([label]))\n",
    "        bag_feats = Variable(Tensor([feats]))\n",
    "    #     sys.stdout.write(f'original label:{bag_label},shape of feats:{bag_feats.shape}\\n')\n",
    "        bag_feats = bag_feats.view(-1, args.feats_size)\n",
    "    #     sys.stdout.write(f'shape of feats after view:{bag_feats.shape}\\n')\n",
    "        ins_prediction, bag_prediction, _, _ = milnet(bag_feats)\n",
    "    #     sys.stdout.write(f'shape of ins_pred:{ins_prediction.shape},original bag_pred:{bag_prediction},shape of original bag_pred:{bag_prediction.shape}\\n')\n",
    "        max_prediction, _ = torch.max(ins_prediction, 0)  \n",
    "        bag_prediction = torch.mean(bag_prediction,dim=0)\n",
    "    #     sys.stdout.write(f'max pred:{max_prediction},bag pred after mean:{bag_prediction}\\n')\n",
    "        bag_loss = criterion(bag_prediction.view(1, -1), bag_label.view(1, -1))\n",
    "        max_loss = criterion(max_prediction.view(1, -1), bag_label.view(1, -1))\n",
    "        loss = 0.5*bag_loss + 0.5*max_loss\n",
    "        total_loss = total_loss + loss.item()\n",
    "    #     sys.stdout.write('\\r Testing bag [%d/%d] bag loss: %.4f \\n' % (i, len(test_df), loss.item()))\n",
    "        test_labels.extend([label])\n",
    "        #test predictions equals to sigmoid（bag prediction）\n",
    "        if args.average:\n",
    "            test_predictions.extend([(0.5*torch.sigmoid(max_prediction)+0.5*torch.sigmoid(bag_prediction)).squeeze().cpu().numpy()])\n",
    "        else: test_predictions.extend([(0.0*torch.sigmoid(max_prediction)+1.0*torch.sigmoid(bag_prediction)).squeeze().cpu().numpy()])\n",
    "#     sys.stdout.write(f'test laels:{label},test prediction : {test_predictions}')\n",
    "test_labels = np.array(test_labels)\n",
    "test_predictions = np.array(test_predictions)\n",
    "auc_value, _, thresholds_optimal = multi_label_roc(test_labels, test_predictions, args.num_classes, pos_label=1)\n",
    "sys.stdout.write(f'auc_value:{auc_value},threshold_optimal:{thresholds_optimal}')\n",
    "if args.num_classes==1:\n",
    "    class_prediction_bag = copy.deepcopy(test_predictions)\n",
    "    class_prediction_bag[test_predictions>=thresholds_optimal[0]] = 1\n",
    "    class_prediction_bag[test_predictions<thresholds_optimal[0]] = 0\n",
    "    test_predictions = class_prediction_bag\n",
    "    test_labels = np.squeeze(test_labels)\n",
    "else:        \n",
    "    for i in range(args.num_classes):\n",
    "        class_prediction_bag = copy.deepcopy(test_predictions[:, i])\n",
    "        class_prediction_bag[test_predictions[:, i]>=thresholds_optimal[i]] = 1\n",
    "        class_prediction_bag[test_predictions[:, i]<thresholds_optimal[i]] = 0\n",
    "        test_predictions[:, i] = class_prediction_bag\n",
    "sys.stdout.write(f'first 5 class_pred_bag:{class_prediction_bag[:5]},first 5 test_pred:{test_predictions[:5]},first 5 labels:{test_labels[:5]}')\n",
    "\n",
    "#todo:将labels / preds改成单个数字，获得混淆矩阵\n",
    "\n",
    "c = confusion_matrix(test_labels,test_predictions).ravel()\n",
    "tn, fp, fn, tp = c.ravel()\n",
    "bag_score = 0\n",
    "for i in range(0, len(test_df)):\n",
    "    bag_score = np.array_equal(test_labels[i], test_predictions[i]) + bag_score       \n",
    "avg_score = bag_score / len(test_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c72eb47f-2147-408a-9966-867971bba292",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "scalar should be 0D",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [48]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorboard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SummaryWriter\n\u001b[1;32m      3\u001b[0m writter \u001b[38;5;241m=\u001b[39m SummaryWriter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest/abc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mwritter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_scalar\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/patho_AI/lib/python3.8/site-packages/torch/utils/tensorboard/writer.py:387\u001b[0m, in \u001b[0;36mSummaryWriter.add_scalar\u001b[0;34m(self, tag, scalar_value, global_step, walltime, new_style, double_precision)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcaffe2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m workspace\n\u001b[1;32m    385\u001b[0m     scalar_value \u001b[38;5;241m=\u001b[39m workspace\u001b[38;5;241m.\u001b[39mFetchBlob(scalar_value)\n\u001b[0;32m--> 387\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[43mscalar\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscalar_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_style\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_style\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdouble_precision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdouble_precision\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_file_writer()\u001b[38;5;241m.\u001b[39madd_summary(summary, global_step, walltime)\n",
      "File \u001b[0;32m~/miniconda3/envs/patho_AI/lib/python3.8/site-packages/torch/utils/tensorboard/summary.py:280\u001b[0m, in \u001b[0;36mscalar\u001b[0;34m(name, scalar, collections, new_style, double_precision)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m\"\"\"Outputs a `Summary` protocol buffer containing a single scalar value.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;124;03mThe generated Summary has a Tensor.proto containing the input Tensor.\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m  ValueError: If tensor has the wrong shape or type.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    279\u001b[0m scalar \u001b[38;5;241m=\u001b[39m make_np(scalar)\n\u001b[0;32m--> 280\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m scalar\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscalar should be 0D\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;66;03m# python float is double precision in numpy\u001b[39;00m\n\u001b[1;32m    282\u001b[0m scalar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(scalar)\n",
      "\u001b[0;31mAssertionError\u001b[0m: scalar should be 0D"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writter = SummaryWriter('test/abc')\n",
    "writter.add_scalar('test',torch.tensor([0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce833fc8-b020-4f5b-802a-5f8be1ef8585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def file_remover(folder):\n",
    "    files = os.listdir(f'./hyperparam_select_batch_9/weights/{folder}')\n",
    "    #change working path\n",
    "    os.chdir(f'./hyperparam_select_batch_9/weights/{folder}')\n",
    "    best_score = []\n",
    "    best_auc = []\n",
    "    best_avg_auc = []\n",
    "\n",
    "    for name in files:\n",
    "        first_num = int(name.split('b')[0])\n",
    "        if 'avg' in name:\n",
    "            best_avg_auc.append(first_num) \n",
    "        elif 'score' in name:\n",
    "            best_score.append(first_num)\n",
    "        elif 'auc' in name:\n",
    "            best_auc.append(first_num)\n",
    "    max_score = max(best_score)  \n",
    "    max_auc = max(best_auc)\n",
    "    max_avg_auc = max(best_avg_auc)\n",
    "#     print(os.getcwd())\n",
    "#     print(f'{max_score}best_score.pth')  \n",
    "#     print(f'{max_auc}best_auc.pth')\n",
    "#     print(f'{max_avg_auc}best_avg_auc.pth')\n",
    "    \n",
    "    #remove files that not satisfy the best\n",
    "    for name in files:\n",
    "        if name not in [f'{max_score}best_score.pth',f'{max_auc}best_auc.pth',f'{max_avg_auc}best_avg_auc.pth']:\n",
    "            os.remove(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "294c2b9a-b1bf-40bd-bcaf-9a2121179f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88best_score.pth\n",
      "88best_auc.pth\n",
      "79best_avg_auc.pth\n",
      "101best_score.pth\n",
      "101best_auc.pth\n",
      "101best_avg_auc.pth\n",
      "163best_score.pth\n",
      "163best_auc.pth\n",
      "163best_avg_auc.pth\n",
      "108best_score.pth\n",
      "108best_auc.pth\n",
      "108best_avg_auc.pth\n",
      "73best_score.pth\n",
      "75best_auc.pth\n",
      "75best_avg_auc.pth\n",
      "79best_score.pth\n",
      "79best_auc.pth\n",
      "79best_avg_auc.pth\n",
      "30best_score.pth\n",
      "30best_auc.pth\n",
      "30best_avg_auc.pth\n",
      "85best_score.pth\n",
      "85best_auc.pth\n",
      "85best_avg_auc.pth\n",
      "93best_score.pth\n",
      "30best_auc.pth\n",
      "26best_avg_auc.pth\n",
      "163best_score.pth\n",
      "163best_auc.pth\n",
      "163best_avg_auc.pth\n"
     ]
    }
   ],
   "source": [
    "#initialize path\n",
    "os.chdir(f'/home/wangyh/uro_biomarker/patho_AI/processing/mil classifier')\n",
    "folder_ls = os.listdir('./hyperparam_select_batch_9/weights/')\n",
    "\n",
    "for folder in folder_ls:\n",
    "    file_remover(folder)\n",
    "    #reset path\n",
    "    os.chdir(f'/home/wangyh/uro_biomarker/patho_AI/processing/mil classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412470f2-7709-4bf8-be8f-266c34de204e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patho_AI",
   "language": "python",
   "name": "patho_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
