{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a812c032-312b-40d5-b3ce-10bba8de10b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangyh/miniconda3/envs/patho_AI/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models as torch_models\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a017673c-3490-4558-92fa-ce407d4a38d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = np.load('../config/data_segmentation_csv/10X_full.npy',allow_pickle=True).item()\n",
    "test_df = data_df['full_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29286470-cee7-49c9-afa0-b9b163981b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "363"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()\n",
    "len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cbbe2e8-b1f0-4bff-88d0-811bcfd6d858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.resnet_simclr import ResNetSimCLR\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3987fbde-386f-4f5a-bf03-2eadd0ac23f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangyh/miniconda3/envs/patho_AI/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/wangyh/miniconda3/envs/patho_AI/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extractor: resnet50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNetSimCLR(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (l1): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "  (l2): Linear(in_features=2048, out_features=512, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load('simclr_feature_extractor/runs/Apr20_10-20-33_ubuntu-T640/checkpoints/model.pth')\n",
    "state_dict = {k.replace('module.',''):v for k,v in state_dict.items()}\n",
    "model = ResNetSimCLR(base_model='resnet50',out_dim=512)\n",
    "model.load_state_dict(state_dict)\n",
    "model = model.eval()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a2a1efd-a47c-49f2-aae1-50d2ff5f0a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_paths = test_df['img_list'].iloc[5]\n",
    "# imgs = []\n",
    "\n",
    "data_transform = transforms.Compose([transforms.Resize(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "# for i in tqdm(img_paths):\n",
    "#     image = Image.open(i).convert('RGB')\n",
    "#     image_tensor = data_transform(image).unsqueeze(0)\n",
    "#     imgs.append(image_tensor)\n",
    "# input = torch.cat(imgs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22afc50e-b55b-46f0-b2cf-6404b8235792",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ce89a3-d76e-4e85-afbf-d17fb9a2258a",
   "metadata": {},
   "source": [
    "#### 单个slide feature extraction测试:通过指定i（iloc，not index）切换不同slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cfd41f0-bab2-4e79-8012-dc263a5f172a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i=202\n",
    "del i\n",
    "batch_size = 64\n",
    "# slide_features = {}\n",
    "# with torch.no_grad():\n",
    "#     paths = test_df['img_list'].iloc[i]\n",
    "#     N_tumor_patch = len(paths)\n",
    "#     feature_list = []\n",
    "#     for batch_idx in tqdm(range(0, N_tumor_patch, batch_size)):\n",
    "#         end = batch_idx + batch_size if batch_idx+batch_size < N_tumor_patch else N_tumor_patch\n",
    "#         batch_paths = paths[batch_idx: end]\n",
    "#         images = []\n",
    "#         for p in batch_paths:\n",
    "#             image = Image.open(p).convert('RGB')\n",
    "#             image_tensor = data_transform(image).unsqueeze(0)\n",
    "#             images.append(image_tensor)\n",
    "#         images = torch.cat(images, dim=0)\n",
    "\n",
    "#         features = model(images.cuda())[1]\n",
    "#         if len(features.shape) == 1:\n",
    "#             features = features.unsqueeze(0)\n",
    "#         feature_list.append(features.detach().cpu())\n",
    "#         del features\n",
    "\n",
    "#     feature_list = torch.cat(feature_list, dim=0)\n",
    "#     slide_features[f'index{i}'] = (test_df['dir_uuid'].iloc[i],test_df['TMB_H/L'].iloc[i],feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "97507655-7de2-4cf2-84a3-aaa2cde4930a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([129, 512])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slide_features[f'index{i}'][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7fce6be2-12d1-4525-9fe2-78c9dfec15f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "s_features = np.load('../data/10X_full_slide_features_res50.npy',allow_pickle=True).item()  #未增加上面cell中关于维度处理时提取的无问题slides\n",
    "unextracted = np.load('../data/10X_full_not_extracted_res50.npy',allow_pickle=True) #有问题的slides的列表\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e177102-ce8e-4c34-8c7e-a090aae7623e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bc09ee8e-ff24-4635-852f-84cabce80c0f',\n",
       " 'L',\n",
       " tensor([[-0.0237,  0.0373, -0.0691,  ..., -0.2615, -0.1424,  0.0990],\n",
       "         [ 0.0070, -0.0482,  0.1075,  ..., -0.1204, -0.0039, -0.1455],\n",
       "         [ 0.1838, -0.0326,  0.1583,  ..., -0.1497, -0.0781, -0.0553],\n",
       "         [-0.0888,  0.1956, -0.2567,  ...,  0.0945,  0.1830, -0.0325],\n",
       "         [-0.3277, -0.1676, -0.2626,  ..., -0.2340,  0.0220, -0.1692]]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_features['index98']\n",
    "# unextracted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acce1669-b1d2-447a-b5a1-2565eb42a148",
   "metadata": {},
   "source": [
    "# slide feature extraction 拯救计划：补充未被提取的图片们"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21a9ece-8fc0-4589-bc40-6e2f3d4e13cb",
   "metadata": {},
   "source": [
    "#### 多个slide feature extraction测试:通过指定i——list（iloc，not index）切换不同slides——series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90975bc5-8533-4ac5-860e-475269019513",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:12<00:00,  1.55s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(unextracted):\n",
    "    try:\n",
    "        paths = test_df['img_list'].iloc[i]\n",
    "        N_tumor_patch = len(paths)\n",
    "        feature_list = []\n",
    "        for batch_idx in range(0, N_tumor_patch, batch_size):\n",
    "            end = batch_idx + batch_size if batch_idx+batch_size < N_tumor_patch else N_tumor_patch\n",
    "            batch_paths = paths[batch_idx: end]\n",
    "            images = []\n",
    "            for p in batch_paths:\n",
    "                image = Image.open(p).convert('RGB')\n",
    "                image_tensor = data_transform(image).unsqueeze(0)\n",
    "                images.append(image_tensor)\n",
    "            images = torch.cat(images, dim=0)\n",
    "\n",
    "            features = model(images.cuda())[1]\n",
    "            if len(features.shape) == 1:\n",
    "                features = features.unsqueeze(0)\n",
    "            feature_list.append(features.detach().cpu())\n",
    "            del features\n",
    "\n",
    "        feature_list = torch.cat(feature_list, dim=0)\n",
    "        s_features[f'index{i}'] = (test_df['dir_uuid'].iloc[i],test_df['TMB_H/L'].iloc[i],feature_list)\n",
    "    except Exception as e:\n",
    "        print(f'wrong in slide{i}, error as {e}')\n",
    "#         unextracted.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9af691ce-565c-4a66-a598-60c990987e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "363"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "407e62f4-6643-4566-a485-3cbbd9fa2f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bc09ee8e-ff24-4635-852f-84cabce80c0f',\n",
       " 'L',\n",
       " tensor([[-0.0237,  0.0373, -0.0691,  ..., -0.2615, -0.1424,  0.0990],\n",
       "         [ 0.0070, -0.0482,  0.1075,  ..., -0.1204, -0.0039, -0.1455],\n",
       "         [ 0.1838, -0.0326,  0.1583,  ..., -0.1497, -0.0781, -0.0553],\n",
       "         [-0.0888,  0.1956, -0.2567,  ...,  0.0945,  0.1830, -0.0325],\n",
       "         [-0.3277, -0.1676, -0.2626,  ..., -0.2340,  0.0220, -0.1692]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_features['index98']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7020b48-b389-4096-ba11-939c1f99fc34",
   "metadata": {},
   "source": [
    "用完全版的slide features覆盖之前的不完全版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0a12bba-0192-4610-984f-c7ad41bec3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('../data/10X_full_slide_features_res50.npy',s_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fa0e35-109d-4e74-9a28-97698fd2a564",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patho_AI",
   "language": "python",
   "name": "patho_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
