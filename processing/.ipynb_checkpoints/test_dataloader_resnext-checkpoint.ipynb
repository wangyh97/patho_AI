{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5589476a-dff6-4d1a-918c-b6a364403b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets\n",
    "import os\n",
    "import glob\n",
    "from random import shuffle\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.io as scio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8258977b-4e4b-422d-951d-163e3beb6fd0",
   "metadata": {},
   "source": [
    "# 以5x做单折测试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e411f3d9-e52c-4764-afe5-0f99a96e96e4",
   "metadata": {},
   "source": [
    "## 分配数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af3ee2b9-0449-4bc7-bbfc-2bd6147e435c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_5x = glob.glob('/mnt/wangyh/CN_patches/*/*/5X/T*')\n",
    "# set of 5x tumor tiles, has a length of 28277"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a29ee94d-5726-46ab-9a66-af5c0297807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5折交叉\n",
    "size_val = len(data_5x)//5\n",
    "# size_train = len(data_5x)- size_val\n",
    "\n",
    "shuffle(data_5x)\n",
    "val = data_5x[:size_val]\n",
    "train = data_5x[size_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db7f183-7376-4589-9052-3398cb26f430",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_EXTENSIONS = ['.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ab6bf1c7-c331-493b-86a8-c94c4e1f39b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImageNetData(args):\n",
    "# data_transform, pay attention that the input of Normalize() is Tensor and the input of RandomResizedCrop() or RandomHorizontalFlip() is PIL Image\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.RandomCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "    image_datasets = {}\n",
    "    #image_datasets['train'] = datasets.ImageFolder(os.path.join(args.data_dir, 'ILSVRC2012_img_train'), data_transforms['train'])\n",
    "\n",
    "    image_datasets['train'] = ImageNetTrainDataSet(os.path.join(args.data_dir, 'ILSVRC2012_img_train'),\n",
    "                                           os.path.join(args.data_dir, 'ILSVRC2012_devkit_t12', 'data', 'meta.mat'),\n",
    "                                           data_transforms['train'])\n",
    "    image_datasets['val'] = ImageNetValDataSet(os.path.join(args.data_dir, 'ILSVRC2012_img_val'),\n",
    "                                               os.path.join(args.data_dir, 'ILSVRC2012_devkit_t12', 'data','ILSVRC2012_validation_ground_truth.txt'),\n",
    "                                               data_transforms['val'])\n",
    "\n",
    "    # wrap your data and label into Tensor\n",
    "    dataloders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                                 batch_size=args.batch_size,\n",
    "                                                 shuffle=True,\n",
    "                                                 num_workers=args.num_workers) for x in ['train', 'val']}\n",
    "\n",
    "\n",
    "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "    return dataloders, dataset_sizes\n",
    "\n",
    "class myDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_list,data_transforms = None):\n",
    "        label_dic = {\n",
    "            'H':0,\n",
    "            'L':1\n",
    "        }\n",
    "        self.img_list = img_list\n",
    "        self.label_dic = label_dic\n",
    "        self.data_transforms = data_transforms\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label_dic = {\n",
    "            'H':0,\n",
    "            'L':1\n",
    "        }\n",
    "        item = self.img_list[index]\n",
    "        img = Image.open(item)\n",
    "        if self.data_transforms is not None:\n",
    "            try:\n",
    "                img = self.data_transforms(img)\n",
    "            except:\n",
    "                print(\"Cannot transform image: {}\".format(self.img_list[index]))\n",
    "        label = label_dic[Path(item).parts[4]]\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5cc612e8-1ebf-4d42-97ad-56cbd0faf027",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "trainingset = myDataSet(train,data_transforms=data_transforms['train'])\n",
    "valset = myDataSet(val,data_transforms=data_transforms['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b6f26f-5eca-404d-93a5-bfc899ed27f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patho_AI",
   "language": "python",
   "name": "patho_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
