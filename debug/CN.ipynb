{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42331134-53a8-4e9d-832b-3d8cf213e56e",
   "metadata": {},
   "source": [
    "# 库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e2119c8-22eb-45ba-bdde-ee46558ba721",
   "metadata": {},
   "outputs": [],
   "source": [
    "openslide_path = {'desktop':'D:/edge下载/openslide-win64-20220811/bin',\n",
    "                'laptop':'E:/openslide-win64-20171122/bin'}\n",
    "package_list = [\n",
    "    '/home/wangyh/uro_biomarker/stain-normalizer/'\n",
    "]\n",
    "import os\n",
    "from pathlib import Path\n",
    "if hasattr(os,'add_dll_directory'):\n",
    "    for i in openslide_path.values():\n",
    "        if Path(i).exists():\n",
    "            with os.add_dll_directory(Path(i)):\n",
    "                import openslide\n",
    "else:\n",
    "    import openslide\n",
    "from openslide.deepzoom import DeepZoomGenerator\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import cv2\n",
    "import skimage\n",
    "from lxml import etree\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "import gc\n",
    "import time\n",
    "import sys\n",
    "import getopt\n",
    "import pandas as pd\n",
    "import glob\n",
    "import tifffile as tif\n",
    "import staintools\n",
    "for i in package_list:\n",
    "    sys.path.append(i)\n",
    "# import StainNormalizer\n",
    "# from StainNormalizer import Normalizer\n",
    "import cupy as cp #用与cuda相符的版本\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8bf218e-435d-4f83-a8b9-4387d90af533",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangyh/miniconda3/envs/patho_AI/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchstain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5c76d9-52cf-415f-9a7c-b22803a849a6",
   "metadata": {},
   "source": [
    "# 函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faa2a6d-06bb-4420-b742-7e780156e16e",
   "metadata": {},
   "source": [
    "## 基本函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9874cf27-89ef-4cbb-a0f4-0900fb4912df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(training,validation,test,fold,labels,threshold=1000000,\n",
    "            absolute=False,remove_large_data_on=False,print_result = False):\n",
    "\n",
    "    def remove_large_data():\n",
    "        nonlocal training, validation, test, fold, labels,threshold\n",
    "        sum = training + validation + test\n",
    "        index = np.where(sum > threshold)\n",
    "        training = np.delete(training, index)\n",
    "        validation = np.delete(validation, index)\n",
    "        test = np.delete(test, index)\n",
    "        labels_copy = labels\n",
    "        labels = [labels_copy[x] for x in range(len(labels_copy)) if x not in np.array(index).tolist()[0]] # index：(array([3, 5, 6], dtype=int64),)，一个tuple，不能够用in直接判断，转成ndarray后再转成list以用in判断之\n",
    "        print('enter remove_large_data')\n",
    "        return training,validation,test,labels\n",
    "        \n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.title('dataset split')\n",
    "\n",
    "    if not absolute:\n",
    "        plt.yticks(np.linspace(0,1,11),labels=np.arange(0,101,10).tolist())\n",
    "        plt.ylabel('percentage')\n",
    "        sum = training+validation+test\n",
    "        bottom = training/sum\n",
    "        center = validation/sum\n",
    "        top = test/sum\n",
    "    else:\n",
    "        if remove_large_data_on:\n",
    "            bottom,center,top,labels = remove_large_data()\n",
    "        else:\n",
    "            bottom = training\n",
    "            center = validation\n",
    "            top = test\n",
    "        plt.yticks(np.linspace(0,np.max(bottom+center+top),10))\n",
    "        plt.ylabel('absolute amount')\n",
    "\n",
    "    N = bottom.size\n",
    "    ind = np.arange(N)\n",
    "    plt.xticks(np.arange(N),labels=labels,rotation=45)\n",
    "\n",
    "    width = 0.35  # 设置条形图一个长条的宽度\n",
    "    p1color = ['dodgerblue' if x else 'royalblue' for x in fold]\n",
    "    p2color = ['chartreuse' if x else 'limegreen'for x in fold]\n",
    "    p3color = ['gold' if x else 'orangered' for x in fold]\n",
    "    if print_result:\n",
    "        print(bottom,center,top,sum,p1color)\n",
    "    else:\n",
    "\n",
    "\n",
    "        p1 = plt.bar(ind, bottom, width, color=p1color)  \n",
    "        p2 = plt.bar(ind, center, width, bottom=bottom,color=p2color)  #在p1的基础上绘制，底部数据就是p1的数据\n",
    "        p3 = plt.bar(ind, top, width, bottom=bottom+center,color=p3color)    #在p1和p2的基础上绘制，底部数据就是p1和p2\n",
    "\n",
    "        plt.legend((p1[1], p2[1], p3[1]), ('training', 'validation', 'test'),loc = 3)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "class Timer():\n",
    "    def __init__(self,proc):\n",
    "        self._begin_time = None\n",
    "        self.proc = proc\n",
    "\n",
    "    def tic(self):\n",
    "        print(f'{self.proc} start!')\n",
    "        self._begin_time = time.perf_counter()\n",
    "\n",
    "    def toc(self):\n",
    "        print(f'{self.proc} finish!,consuming {time.perf_counter() - self._begin_time}')\n",
    "        return time.perf_counter() - self._begin_time\n",
    "\n",
    "def binary_conversion(var):\n",
    "    \"\"\"\n",
    "    二进制单位转换\n",
    "    :param var: 需要计算的变量，bytes值\n",
    "    :return: 单位转换后的变量，kb 或 mb\n",
    "    \"\"\"\n",
    "    var_size = sys.getsizeof(var)\n",
    "    assert isinstance(var_size, int)\n",
    "    if var_size <= 1024:\n",
    "        return f'占用 {round(var_size / 1024, 2)} KB内存'\n",
    "    else:\n",
    "        return f'占用 {round(var_size / (1024 ** 2), 2)} MB内存'\n",
    "    \n",
    "def show_info(show_OI = False,show_values = False,**kws):\n",
    "    length = 'no length'\n",
    "    keys = 'not a dict'\n",
    "    values = 'not a dict'\n",
    "    shape = 'not a ndarray'\n",
    "    size = 'not a ndarray'\n",
    "    for key,x in kws.items():\n",
    "        if hasattr(x,'__len__'):\n",
    "            length = len(x)\n",
    "        if isinstance(x,dict):\n",
    "            keys = x.keys()\n",
    "            values = x.values()\n",
    "        if type(x) is np.ndarray or type(x) is cp.ndarray or type(x) is torch.Tensor:\n",
    "            shape = x.shape\n",
    "            size = x.size\n",
    "        print(key)\n",
    "        print(f'allocated memory:{binary_conversion(x)}')\n",
    "        print(f'\\ntype:{type(x)} \\nlen:{length}\\nshape:{shape}\\nsize:{size}\\nkeys:{keys}\\n')\n",
    "        if show_OI:\n",
    "            print(f'original info:{x}\\n')\n",
    "        if show_values:\n",
    "            print(f'\\nvalues:{values}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee60c4f-880b-4086-86ee-2f6b9d90582f",
   "metadata": {},
   "source": [
    "## 图片可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d85fcc59-881e-470a-8b65-8ff380af7996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_or_not(x,pr = False):  #只要有一个元素不为0则不为0\n",
    "    if type(x) is not np.ndarray:\n",
    "        x = np.array(x)\n",
    "    if pr:\n",
    "        if x.any():\n",
    "            print('not all 0')\n",
    "        else:\n",
    "            print('all 0')\n",
    "    return x.any()\n",
    "\n",
    "def show_dzg_info(dzg):\n",
    "    print(f'level count:{dzg.level_count}')\n",
    "    print(f'tile arrangement of last 3 level{dzg.level_tiles[-4:-1]}\\ndimensions of each tile at last 3 level:{dzg.level_dimensions[-4:-1]}')\n",
    "\n",
    "def pop_tile(dzg,level,save = False):\n",
    "    row,col = dzg.level_tiles[level]\n",
    "    saved = []\n",
    "    if level<0:\n",
    "        level = dzg.level_count + level\n",
    "    for i in range(row):\n",
    "        for j in range(col):\n",
    "            if null_or_not(dzg.get_tile(level,(i,j))):\n",
    "                saved.append((i,j))\n",
    "                if not save:\n",
    "                    print((i,j))\n",
    "    if save:\n",
    "        return saved\n",
    "\n",
    "def pixel_255(image,point = False,threshold = False):\n",
    "    if type(image) is not np.ndarray:\n",
    "        image = np.array(image)\n",
    "        if point:\n",
    "            image[image==0] = 255\n",
    "        if threshold:\n",
    "            image[image>threshold] = 255 \n",
    "        return Image.fromarray(image)\n",
    "    else:\n",
    "        if point:\n",
    "            image[image==0] = 255\n",
    "        if threshold:\n",
    "            image[image>threshold] = 255 \n",
    "        return image\n",
    "\n",
    "#通过cv显示图片\n",
    "def imgshow(img_path):\n",
    "    tiff = cv2.imread(img_path)\n",
    "    plt.imshow(Image.fromarray(tiff))\n",
    "\n",
    "#查看tiff文件path、info及图片\n",
    "def tiff_checker(tiff_path):\n",
    "    show_info(tiff_path = tiff_path)\n",
    "    tif.imshow(tif.imread(tiff_path))\n",
    "\n",
    "#同时展示多张图片\n",
    "def ploting(rows,cols,figseq,\n",
    "            figsize=(20,20),fontdict={'size':20},title = []):\n",
    "    #figseq是一个4维的ndarray\n",
    "    #rows,cols是展示图片的行/列数\n",
    "    fig,axes = plt.subplots(rows,cols,figsize=figsize)\n",
    "    fontdict = fontdict\n",
    "    if rows != 1:\n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                if title:\n",
    "                    axes[i,j].set_title(title[i*cols+j])\n",
    "                else:\n",
    "                    axes[i,j].set_title(f'{i}_{j}')\n",
    "                axes[i,j].imshow(figseq[i*cols+j])\n",
    "    else:\n",
    "        for j in range(cols):\n",
    "            if title:\n",
    "                axes[j].set_title(title[j])\n",
    "            else:\n",
    "                axes[j].set_title(f'{j}')\n",
    "            axes[j].imshow(figseq[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c17d427-a943-414b-90e1-dc3d89fbdf5d",
   "metadata": {},
   "source": [
    "## stainnormalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25f6e82d-5766-4b2c-afad-5e4bc071ef92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#切割的图片大小大多为512，normalization将非512*512的去除，大约占比为10%\n",
    "def gen_normal_size(I_list,target_shape=(512,512,3)):\n",
    "    for i in I_list:\n",
    "        try:\n",
    "            tiff = tif.imread(i)\n",
    "            if tiff.shape == target_shape:\n",
    "                yield i\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "\n",
    "#normalizer类\n",
    "class HENormalizer:\n",
    "    def fit(self, target):\n",
    "        pass\n",
    "\n",
    "    def normalize(self, I, **kwargs):\n",
    "        raise Exception('Abstract method')\n",
    "\n",
    "\"\"\"\n",
    "Inspired by torchstain :\n",
    "Source code adapted from: https://github.com/schaugf/HEnorm_python;\n",
    "Original implementation: https://github.com/mitkovetta/staining-normalization\n",
    "\"\"\"\n",
    "class Normalizer(HENormalizer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.HERef = cp.array([[0.5626, 0.2159],\n",
    "                          [0.7201, 0.8012],\n",
    "                          [0.4062, 0.5581]])\n",
    "        self.maxCRef = cp.array([1.9705, 1.0308])\n",
    "\n",
    "    def __convert_rgb2od(self, I, Io=240, beta=0.15):\n",
    "        # calculate optical density\n",
    "        OD = -cp.log((I.astype(cp.float32)+1)/Io)\n",
    "\n",
    "        # remove transparent pixels\n",
    "        ODhat = OD[~cp.any(OD < beta, axis=1)]\n",
    "\n",
    "        return OD, ODhat\n",
    "\n",
    "    def __find_HE(self, ODhat, eigvecs, alpha):\n",
    "        #project on the plane spanned by the eigenvectors corresponding to the two\n",
    "        # largest eigenvalues\n",
    "        That = ODhat.dot(eigvecs[:,1:3])\n",
    "\n",
    "        phi = cp.arctan2(That[:,1],That[:,0])\n",
    "\n",
    "        minPhi = cp.percentile(phi, alpha)\n",
    "        maxPhi = cp.percentile(phi, 100-alpha)\n",
    "\n",
    "        vMin = eigvecs[:,1:3].dot(cp.array([(cp.cos(minPhi), cp.sin(minPhi))]).T)\n",
    "        vMax = eigvecs[:,1:3].dot(cp.array([(cp.cos(maxPhi), cp.sin(maxPhi))]).T)\n",
    "\n",
    "        # a heuristic to make the vector corresponding to hematoxylin first and the\n",
    "        # one corresponding to eosin second\n",
    "        if vMin[0] > vMax[0]:\n",
    "            HE = cp.array((vMin[:,0], vMax[:,0])).T\n",
    "        else:\n",
    "            HE = cp.array((vMax[:,0], vMin[:,0])).T\n",
    "\n",
    "        return HE\n",
    "\n",
    "    def __find_concentration(self, OD, HE):\n",
    "        # rows correspond to channels (RGB), columns to OD values\n",
    "        Y = cp.reshape(OD, (-1, 3)).T\n",
    "\n",
    "        # determine concentrations of the individual stains\n",
    "        C = cp.linalg.lstsq(HE, Y, rcond=None)[0]\n",
    "\n",
    "        return C\n",
    "\n",
    "    def __compute_matrices(self, I, Io, alpha, beta):\n",
    "        I = I.reshape((-1,3))\n",
    "\n",
    "        OD, ODhat = self.__convert_rgb2od(I, Io=Io, beta=beta)\n",
    "\n",
    "        # compute eigenvectors\n",
    "        _, eigvecs = cp.linalg.eigh(cp.cov(ODhat.T))\n",
    "\n",
    "        HE = self.__find_HE(ODhat, eigvecs, alpha)\n",
    "\n",
    "        C = self.__find_concentration(OD, HE)\n",
    "\n",
    "        # normalize stain concentrations\n",
    "        maxC = cp.array([cp.percentile(C[0,:], 99), cp.percentile(C[1,:],99)])\n",
    "\n",
    "        return HE, C, maxC\n",
    "\n",
    "    def fit(self, I, Io=240, alpha=1, beta=0.15):\n",
    "        I = cp.asarray(I)\n",
    "        HE, _, maxC = self.__compute_matrices(I, Io, alpha, beta)\n",
    "\n",
    "        self.HERef = HE\n",
    "        self.maxCRef = maxC\n",
    "\n",
    "    def normalize(self, I, Io=240, alpha=1, beta=0.15):\n",
    "        ''' Normalize staining appearence of H&E stained images\n",
    "        Example use:\n",
    "            see test.py\n",
    "        Input:\n",
    "            I: RGB input image\n",
    "            Io: (optional) transmitted light intensity\n",
    "        Output:\n",
    "            Inorm: normalized image\n",
    "            H: hematoxylin image\n",
    "            E: eosin image\n",
    "        Reference:\n",
    "            A method for normalizing histology slides for quantitative analysis. M.\n",
    "            Macenko et al., ISBI 2009\n",
    "        '''\n",
    "       # I = cp.asarray(I)\n",
    "        batch,h, w, c = I.shape\n",
    "        I = I.reshape((-1,3))\n",
    "\n",
    "        HE, C, maxC = self.__compute_matrices(I, Io, alpha, beta)\n",
    "\n",
    "        maxC = cp.divide(maxC, self.maxCRef)\n",
    "        C2 = cp.divide(C, maxC[:, cp.newaxis])\n",
    "\n",
    "        # recreate the image using reference mixing matrix\n",
    "        Inorm = cp.multiply(Io, cp.exp(-self.HERef.dot(C2)))\n",
    "        Inorm[Inorm > 255] = 255\n",
    "        Inorm = cp.reshape(Inorm.T, (batch,h, w, c)).astype(cp.uint8)\n",
    "\n",
    "\n",
    "\n",
    "        return Inorm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd899cbf-6a40-4acf-9326-8bb580f42dfd",
   "metadata": {},
   "source": [
    "# debug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607fb51b-565d-4ddd-9930-46df06940739",
   "metadata": {},
   "source": [
    "## 测试程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7ba34cd-2b38-4146-a380-578ece3d5cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = glob.glob(f\"/mnt/wangyh/TCGA_patches/*/*/\")\n",
    "cn_path_test = '/home/wangyh/uro_biomarker/patho_AI/CN_test/'\n",
    "cases_select = cases[:10]\n",
    "\n",
    "# mempool = cp.get_default_memory_pool()\n",
    "# pinned_mempool = cp.get_default_pinned_memory_pool()\n",
    "\n",
    "template_paths = [i for i in gen_normal_size(glob.glob('/mnt/wangyh/TCGA_patches/H/c7bcb827-9da0-4b07-8065-3ce01befec13/40X/*.tiff'))]\n",
    "template_file = pixel_255(tif.TiffSequence(template_paths[:100]).asarray(),point=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f31d99-1d1c-4873-8ea8-aa64907406cc",
   "metadata": {},
   "source": [
    "## 初始化normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5116638-7619-4397-afce-0a0e3f8976f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangyh/miniconda3/envs/patho_AI/lib/python3.8/site-packages/torchstain/torch/normalizers/macenko.py:58: UserWarning: torch.symeig is deprecated in favor of torch.linalg.eigh and will be removed in a future PyTorch release.\n",
      "The default behavior has changed from using the upper triangular portion of the matrix by default to using the lower triangular portion.\n",
      "L, _ = torch.symeig(A, upper=upper)\n",
      "should be replaced with\n",
      "L = torch.linalg.eigvalsh(A, UPLO='U' if upper else 'L')\n",
      "and\n",
      "L, V = torch.symeig(A, eigenvectors=True)\n",
      "should be replaced with\n",
      "L, V = torch.linalg.eigh(A, UPLO='U' if upper else 'L') (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484810403/work/aten/src/ATen/native/BatchLinearAlgebra.cpp:3029.)\n",
      "  _, eigvecs = torch.symeig(cov(ODhat.T), eigenvectors=True)\n",
      "/home/wangyh/miniconda3/envs/patho_AI/lib/python3.8/site-packages/torchstain/torch/normalizers/macenko.py:52: UserWarning: torch.lstsq is deprecated in favor of torch.linalg.lstsq and will be removed in a future PyTorch release.\n",
      "torch.linalg.lstsq has reversed arguments and does not return the QR decomposition in the returned tuple (although it returns other information about the problem).\n",
      "To get the qr decomposition consider using torch.linalg.qr.\n",
      "The returned solution in torch.lstsq stored the residuals of the solution in the last m - n columns of the returned value whenever m > n. In torch.linalg.lstsq, the residuals in the field 'residuals' of the returned named tuple.\n",
      "The unpacking of the solution, as in\n",
      "X, _ = torch.lstsq(B, A).solution[:A.size(1)]\n",
      "should be replaced with\n",
      "X = torch.linalg.lstsq(A, B).solution (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484810403/work/aten/src/ATen/native/BatchLinearAlgebra.cpp:4158.)\n",
      "  return torch.lstsq(Y, HE)[0][:2]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "use staintools\n",
    "'''\n",
    "# # Read data\n",
    "# target = staintools.read_image(template_paths[27])\n",
    "\n",
    "# # Standardize brightness (optional, can improve the tissue mask calculation)\n",
    "# target = staintools.LuminosityStandardizer.standardize(pixel_255(target,point=True))\n",
    "\n",
    "# # Stain normalize initializatino\n",
    "# normalizer = staintools.StainNormalizer(method='vahadane')\n",
    "# normalizer.fit(target)\n",
    "\n",
    "'''\n",
    "use stain_normalizer\n",
    "'''\n",
    "# SN_normalizer = Normalizer()\n",
    "# SN_normalizer.fit(template_file[11])\n",
    "# # target_tile = cp.asarray(target_tiles[:50])\n",
    "# # SN_normed = SN_normalizer.normalize(target_tile)\n",
    "\n",
    "'''\n",
    "use torchstain\n",
    "'''\n",
    "template = cv2.cvtColor(cv2.imread(template_paths[11]), cv2.COLOR_BGR2RGB)\n",
    "T = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x*255)\n",
    "])\n",
    "\n",
    "torch_normalizer = torchstain.normalizers.MacenkoNormalizer(backend='torch')\n",
    "torch_normalizer.fit(T(template))\n",
    "\n",
    "unnorm_tiles = []\n",
    "\n",
    "print(len(cases_select))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13352250-8c29-4e27-8b97-6c983e749eba",
   "metadata": {},
   "source": [
    "### 使用tif.imread读取即可。返回一个RGB的np.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fc23aa3-8450-4213-a04b-ecf4c446c5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# template = cv2.cvtColor(cv2.imread(template_paths[11]),cv2.COLOR_RGB2BGR)\n",
    "# show_info(t = template,tf = template_file[11])\n",
    "# template == template_file[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5aa237d-06dc-4400-9519-5e1501a88acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:00<00:00,  9.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10578\n",
      "name 'mempool' is not defined\n",
      "/mnt/wangyh/TCGA_patches/L/9cf7130c-f381-45df-ae0a-c14017637537/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:00<00:01,  7.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10666\n",
      "'torch.dtype' object has no attribute 'char'\n",
      "/mnt/wangyh/TCGA_patches/L/1f24af21-9bb4-409f-8bbc-5a0e56d777ab/40X/nonT_140_76.tiff\n",
      "name 'mempool' is not defined\n",
      "/mnt/wangyh/TCGA_patches/L/1f24af21-9bb4-409f-8bbc-5a0e56d777ab/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:00<00:01,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15787\n",
      "'torch.dtype' object has no attribute 'char'\n",
      "/mnt/wangyh/TCGA_patches/L/0fcdc140-1ee5-4c7a-a210-f2b4990690af/40X/nonT_106_31.tiff\n",
      "name 'mempool' is not defined\n",
      "/mnt/wangyh/TCGA_patches/L/0fcdc140-1ee5-4c7a-a210-f2b4990690af/\n",
      "11502\n",
      "'torch.dtype' object has no attribute 'char'\n",
      "/mnt/wangyh/TCGA_patches/L/cc9af55a-6ee4-4af3-bd35-8b83ea397663/40X/nonT_271_91.tiff\n",
      "name 'mempool' is not defined\n",
      "/mnt/wangyh/TCGA_patches/L/cc9af55a-6ee4-4af3-bd35-8b83ea397663/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:00<00:00,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20950\n",
      "'torch.dtype' object has no attribute 'char'\n",
      "/mnt/wangyh/TCGA_patches/L/b78959f2-43fb-419c-83d2-b7ea35c3606a/40X/T_31_106.tiff\n",
      "name 'mempool' is not defined\n",
      "/mnt/wangyh/TCGA_patches/L/b78959f2-43fb-419c-83d2-b7ea35c3606a/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:01<00:00,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11922\n",
      "'torch.dtype' object has no attribute 'char'\n",
      "/mnt/wangyh/TCGA_patches/L/69d09faa-615f-4923-8342-b8c642790fbf/40X/T_76_81.tiff\n",
      "name 'mempool' is not defined\n",
      "/mnt/wangyh/TCGA_patches/L/69d09faa-615f-4923-8342-b8c642790fbf/\n",
      "11270\n",
      "'torch.dtype' object has no attribute 'char'\n",
      "/mnt/wangyh/TCGA_patches/L/c15c23f2-aa30-45ce-bc83-0e3158779250/40X/T_76_81.tiff\n",
      "name 'mempool' is not defined\n",
      "/mnt/wangyh/TCGA_patches/L/c15c23f2-aa30-45ce-bc83-0e3158779250/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:01<00:00,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8676\n",
      "'torch.dtype' object has no attribute 'char'\n",
      "/mnt/wangyh/TCGA_patches/L/5dd71f48-ba3e-46e4-b1d6-164722a3e06a/40X/T_76_81.tiff\n",
      "name 'mempool' is not defined\n",
      "/mnt/wangyh/TCGA_patches/L/5dd71f48-ba3e-46e4-b1d6-164722a3e06a/\n",
      "15632\n",
      "'torch.dtype' object has no attribute 'char'\n",
      "/mnt/wangyh/TCGA_patches/L/62eda100-574d-49b8-8dc3-3f58fbdc38d4/40X/nonT_221_90.tiff\n",
      "name 'mempool' is not defined\n",
      "/mnt/wangyh/TCGA_patches/L/62eda100-574d-49b8-8dc3-3f58fbdc38d4/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8245\n",
      "'torch.dtype' object has no attribute 'char'\n",
      "/mnt/wangyh/TCGA_patches/L/cf1884cf-8262-45b4-841a-e1ef212c0a3a/40X/nonT_106_31.tiff\n",
      "name 'mempool' is not defined\n",
      "/mnt/wangyh/TCGA_patches/L/cf1884cf-8262-45b4-841a-e1ef212c0a3a/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for case in tqdm(cases_select):\n",
    "    label = Path(case).parent.name\n",
    "    tiles = list(Path(case).rglob(\"*/*\"))\n",
    "    print(len(tiles))\n",
    "    try:\n",
    "        for tile in tiles:\n",
    "            try:\n",
    "                tile_name = str(tile).replace('/mnt/wangyh/TCGA_patches/',cn_path_test)  #transformed tile的存放路径\n",
    "                if not Path(tile_name).exists():\n",
    "                    if not Path(tile_name).parent.exists():\n",
    "                        Path(tile_name).parent.mkdir(parents=True)\n",
    "                        \n",
    "                    tile_img = tif.imread(str(tile))  #读取to_transformed tile\n",
    "                    if tile_img.shape[0] != 512 or tile_img.shape[1] != 512:\n",
    "                        tile_img = Image.fromarray(np.uint8(tile_img)).resize((512,512),Image.ANTIALIAS)\n",
    "                        tile_img = np.asarray(tile_img)\n",
    "                    #tile_name = str(tile).replace\n",
    "                   # tile_img = tif.imread(str(tile))\n",
    "                    #print(tile_img)\n",
    "                    \n",
    "                    '''\n",
    "                    staintools\n",
    "                    '''\n",
    "#                     lum_stand_tile = staintools.LuminosityStandardizer.standardize(pixel_255(tile_img,point=True))\n",
    "#                     norm_imgs = normalizer.transform(lum_stand_tile)\n",
    "                    \n",
    "                    '''\n",
    "                    stain_normalizer\n",
    "                    '''\n",
    "#                     tile_img = tile_img.reshape(1,512,512,3)\n",
    "#                     imgs = cp.asarray(tile_img,dtype=cp.float64)\n",
    "#                     norm_imgs= cp.asnumpy(SN_normalizer.normalize(I=imgs))\n",
    "#                     norm_imgs = norm_imgs.reshape(512,512,3)\n",
    "                    \n",
    "                    '''\n",
    "                    torchstain\n",
    "                    '''\n",
    "                    t_tile_img = T(tile_img)\n",
    "                    norm_imgs,_H,_E = torch_normalizer.normalize(I = t_tile_img,stains = True)\n",
    "                \n",
    "                    tif.imsave(tile_name,norm_imgs)\n",
    "                   # Image.fromarray(np.uint8(norm_imgs)).save(tile_name)\n",
    "            except Exception as e:\n",
    "                    print(e)\n",
    "                    print(tile)\n",
    "                    unnorm_tiles.append(tile)\n",
    "            #norm_imgs = None\n",
    "            imgs = None\n",
    "            mempool.free_all_blocks() \n",
    "            pinned_mempool.free_all_blocks()\n",
    "            gc.collect() \n",
    "     \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(case) \n",
    "        continue\n",
    "np.save(f\"{cn_path_test}.npy\",np.asarray(unnorm_tiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50bd750-94f9-4dd3-b7bd-2d47c6587b39",
   "metadata": {},
   "source": [
    "## 错误1：触发内存错误"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36792bea-049b-44f1-b98e-c97405d4ef02",
   "metadata": {},
   "source": [
    "### 在测试时引起崩溃的文件：\n",
    "\n",
    "/mnt/wangyh/TCGA_patches/L/1f24af21-9bb4-409f-8bbc-5a0e56d777ab/40X/nonT_222_59.tiff\n",
    "\n",
    "/mnt/wangyh/TCGA_patches/L/8805e6a4-3c48-4f9d-ad45-442891b79908/40X/nonT_4_105.tiff\n",
    "\n",
    "/mnt/wangyh/TCGA_patches/L/95cbd3e7-5d6a-428a-a2de-1c20b56896f6/40X/nonT_68_8.tiff\n",
    "\n",
    "/mnt/wangyh/TCGA_patches/H/4311c81b-9c1e-4d86-934d-cdc003444da7/40X/nonT_91_54.tiff\n",
    "\n",
    "### 诱发错误的步骤：\n",
    "\n",
    "cp.asarray()\n",
    "\n",
    "### 报错内容：\n",
    "\n",
    "cudaErrorIllegalAddress: an illegal memory access was encountered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ed42a3-04e4-4373-a5d8-ad54d7258f53",
   "metadata": {},
   "source": [
    "### 查看图片信息是否有异常"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5b0f1fe-8aa3-4e08-9b4b-aeda9711c919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pic_1 = tif.imread('/mnt/wangyh/TCGA_patches/L/1f24af21-9bb4-409f-8bbc-5a0e56d777ab/40X/nonT_222_59.tiff')\n",
    "# pic_2 = tif.imread('/mnt/wangyh/TCGA_patches/L/8805e6a4-3c48-4f9d-ad45-442891b79908/40X/nonT_4_105.tiff')\n",
    "# pic_3 = tif.imread('/mnt/wangyh/TCGA_patches/L/95cbd3e7-5d6a-428a-a2de-1c20b56896f6/40X/nonT_68_8.tiff')\n",
    "# pic_4 = tif.imread('/mnt/wangyh/TCGA_patches/H/4311c81b-9c1e-4d86-934d-cdc003444da7/40X/nonT_91_54.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e15ff117-3487-4c16-8101-5f317208c63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_info(\n",
    "#     _1 = pic_1,\n",
    "#     _2 = pic_2,\n",
    "#     _3 = pic_3,\n",
    "#     _4 = pic_4,show_OI =False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae775db-70c4-4b09-9b88-9d865a5b5fbf",
   "metadata": {},
   "source": [
    "### 单独进行cp.asarray又不再报错？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b44b0ab3-83dc-43dc-8f5e-cc14a6e4bfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_info(c = cp.asarray(pic_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22f61eb-d524-4639-a412-88b175a88616",
   "metadata": {},
   "source": [
    "## 错误2：cannot reshape into... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9921f81-817c-478f-9c0e-6b4f4b978355",
   "metadata": {},
   "source": [
    "3/4_CN.out\n",
    "\n",
    "示例图片：\n",
    "\n",
    "/mnt/wangyh/TCGA_patches/L/bd498605-3c8a-48cf-a47f-ec98b4c606d7/40X/nonT_139_161.tiff\n",
    "\n",
    "/mnt/wangyh/TCGA_patches/L/bd498605-3c8a-48cf-a47f-ec98b4c606d7/20X/nonT_68_80.tiff\n",
    "\n",
    "/mnt/wangyh/TCGA_patches/L/bd498605-3c8a-48cf-a47f-ec98b4c606d7/10X/nonT_34_40.tiff\n",
    "\n",
    "/mnt/wangyh/TCGA_patches/L/bd498605-3c8a-48cf-a47f-ec98b4c606d7/5X/nonT_17_20.tiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d88a647a-ada3-45e9-8063-3a40a582e4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rpic_1 = tif.imread('/mnt/wangyh/TCGA_patches/L/bd498605-3c8a-48cf-a47f-ec98b4c606d7/40X/nonT_139_161.tiff')\n",
    "# Rpic_2 = tif.imread('/mnt/wangyh/TCGA_patches/L/bd498605-3c8a-48cf-a47f-ec98b4c606d7/20X/nonT_68_80.tiff')\n",
    "# Rpic_3 = tif.imread('/mnt/wangyh/TCGA_patches/L/bd498605-3c8a-48cf-a47f-ec98b4c606d7/10X/nonT_34_40.tiff')\n",
    "# Rpic_4 = tif.imread('/mnt/wangyh/TCGA_patches/L/bd498605-3c8a-48cf-a47f-ec98b4c606d7/5X/nonT_17_20.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7563fc23-6f78-4376-8462-e18e66624aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_info(\n",
    "#     _1 = Rpic_1,\n",
    "#     _2 = Rpic_2,\n",
    "#     _3 = Rpic_3,\n",
    "#     _4 = Rpic_4,show_OI =False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f98179-0862-4a8b-8495-248508ab7858",
   "metadata": {},
   "source": [
    "### 可以被resize解决"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad986ad-5734-49e5-9625-dfd30062f57c",
   "metadata": {},
   "source": [
    "#### 测试不同Image方法的异同，肉眼无法发现差异"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08a0a928-018c-452c-b475-8e56e2951937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tile_img_anti = Image.fromarray(np.uint8(Rpic_1)).resize((512,512),Image.ANTIALIAS)\n",
    "# tile_img_anti = np.asarray(tile_img_anti)\n",
    "\n",
    "# tile_img_N = Image.fromarray(np.uint8(Rpic_1)).resize((512,512),Image.NEAREST)\n",
    "# tile_img_N = np.asarray(tile_img_N)\n",
    "\n",
    "# tile_img_bil = Image.fromarray(np.uint8(Rpic_1)).resize((512,512),Image.BILINEAR)\n",
    "# tile_img_bil = np.asarray(tile_img_bil)\n",
    "\n",
    "# tile_img_bic = Image.fromarray(np.uint8(Rpic_1)).resize((512,512),Image.BICUBIC)\n",
    "# tile_img_bic = np.asarray(tile_img_bic)\n",
    "\n",
    "# ploting(1,5,figseq = [Rpic_1,tile_img_anti,tile_img_N,tile_img_bil,tile_img_bic],title = ['original','antialias','nearest','bilinear','bicubic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5df2ef6-f61d-45f8-a212-efb93dfd37fc",
   "metadata": {},
   "source": [
    "# 解决问题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed4cc6d-e80c-4932-9e45-9a3a0aabd24b",
   "metadata": {},
   "source": [
    "## 换成torchstain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28ce5900-5d47-4cc9-9caf-973c2a7383a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = cv2.cvtColor(cv2.imread(template_paths[11]), cv2.COLOR_BGR2RGB)\n",
    "target_1 = cv2.cvtColor(cv2.imread(\"/mnt/wangyh/TCGA_patches/L/1f24af21-9bb4-409f-8bbc-5a0e56d777ab/40X/nonT_222_59.tiff\"), cv2.COLOR_BGR2RGB) #报错文件\n",
    "target_2 = cv2.cvtColor(cv2.imread(\"/mnt/wangyh/TCGA_patches/L/1f24af21-9bb4-409f-8bbc-5a0e56d777ab/40X/nonT_192_57.tiff\"), cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ca11036-f505-4707-bf07-9317485bed5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x*255)\n",
    "])\n",
    "\n",
    "torch_normalizer = torchstain.normalizers.MacenkoNormalizer(backend='torch')\n",
    "torch_normalizer.fit(T(template))\n",
    "\n",
    "t_to_transform_2 = T(target_2)\n",
    "norm_1, H_1, E_1 = torch_normalizer.normalize(I=t_to_transform_2, stains=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2ee9894-d048-4e22-88bb-2a62813e504d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "kthvalue(): Expected reduction dim 0 to have non-zero size.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m t_to_transform_1 \u001b[38;5;241m=\u001b[39m T(target_1)\n\u001b[0;32m----> 2\u001b[0m norm, H, E \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_normalizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mI\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt_to_transform_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/patho_AI/lib/python3.8/site-packages/torchstain/torch/normalizers/macenko.py:98\u001b[0m, in \u001b[0;36mTorchMacenkoNormalizer.normalize\u001b[0;34m(self, I, Io, alpha, beta, stains)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m''' Normalize staining appearence of H&E stained images\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03mExample use:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m    Macenko et al., ISBI 2009\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     96\u001b[0m c, h, w \u001b[38;5;241m=\u001b[39m I\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m---> 98\u001b[0m HE, C, maxC \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__compute_matrices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mI\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# normalize stain concentrations\u001b[39;00m\n\u001b[1;32m    101\u001b[0m C \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxCRef \u001b[38;5;241m/\u001b[39m maxC)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/patho_AI/lib/python3.8/site-packages/torchstain/torch/normalizers/macenko.py:61\u001b[0m, in \u001b[0;36mTorchMacenkoNormalizer.__compute_matrices\u001b[0;34m(self, I, Io, alpha, beta)\u001b[0m\n\u001b[1;32m     58\u001b[0m _, eigvecs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msymeig(cov(ODhat\u001b[38;5;241m.\u001b[39mT), eigenvectors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     59\u001b[0m eigvecs \u001b[38;5;241m=\u001b[39m eigvecs[:, [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m]]\n\u001b[0;32m---> 61\u001b[0m HE \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__find_HE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mODhat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meigvecs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m C \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__find_concentration(OD, HE)\n\u001b[1;32m     64\u001b[0m maxC \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([percentile(C[\u001b[38;5;241m0\u001b[39m, :], \u001b[38;5;241m99\u001b[39m), percentile(C[\u001b[38;5;241m1\u001b[39m, :], \u001b[38;5;241m99\u001b[39m)])\n",
      "File \u001b[0;32m~/miniconda3/envs/patho_AI/lib/python3.8/site-packages/torchstain/torch/normalizers/macenko.py:35\u001b[0m, in \u001b[0;36mTorchMacenkoNormalizer.__find_HE\u001b[0;34m(self, ODhat, eigvecs, alpha)\u001b[0m\n\u001b[1;32m     32\u001b[0m That \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(ODhat, eigvecs)\n\u001b[1;32m     33\u001b[0m phi \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39matan2(That[:, \u001b[38;5;241m1\u001b[39m], That[:, \u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 35\u001b[0m minPhi \u001b[38;5;241m=\u001b[39m \u001b[43mpercentile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m maxPhi \u001b[38;5;241m=\u001b[39m percentile(phi, \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m-\u001b[39m alpha)\n\u001b[1;32m     38\u001b[0m vMin \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(eigvecs, torch\u001b[38;5;241m.\u001b[39mstack((torch\u001b[38;5;241m.\u001b[39mcos(minPhi), torch\u001b[38;5;241m.\u001b[39msin(minPhi))))\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/patho_AI/lib/python3.8/site-packages/torchstain/torch/utils/percentile.py:24\u001b[0m, in \u001b[0;36mpercentile\u001b[0;34m(t, q)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Note that ``kthvalue()`` works one-based, i.e. the first sorted value\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# indeed corresponds to k=1, not k=0! Use float(q) instead of q directly,\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# so that ``round()`` returns an integer, even if q is a np.float32.\u001b[39;00m\n\u001b[1;32m     23\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mround\u001b[39m(\u001b[38;5;241m.01\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mfloat\u001b[39m(q) \u001b[38;5;241m*\u001b[39m (t\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkthvalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mvalues\n",
      "\u001b[0;31mIndexError\u001b[0m: kthvalue(): Expected reduction dim 0 to have non-zero size."
     ]
    }
   ],
   "source": [
    "t_to_transform_1 = T(target_1)\n",
    "norm, H, E = torch_normalizer.normalize(I=t_to_transform_1, stains=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5715641-6d49-47be-8faa-a17a4eb68662",
   "metadata": {},
   "outputs": [],
   "source": [
    "ploting(1,4,figseq=[target_2,norm_1,H_1,E_1],title=['target','norm','H','E'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa99d279-3e32-4cf4-ad0c-f0e9046e01e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_info(t1 = target_1,t2 = target_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patho_AI",
   "language": "python",
   "name": "patho_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
