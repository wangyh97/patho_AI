{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dca8947b-dd3a-4385-9de1-576f9b99c26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "openslide_path = {'desktop':'D:/edge下载/openslide-win64-20220811/bin',\n",
    "                'laptop':'E:/openslide-win64-20171122/bin'}\n",
    "package_list = [\n",
    "    '/home/wangyh/uro_biomarker/stain-normalizer/'\n",
    "]\n",
    "import os\n",
    "from pathlib import Path\n",
    "if hasattr(os,'add_dll_directory'):\n",
    "    for i in openslide_path.values():\n",
    "        if Path(i).exists():\n",
    "            with os.add_dll_directory(Path(i)):\n",
    "                import openslide\n",
    "else:\n",
    "    import openslide\n",
    "from openslide.deepzoom import DeepZoomGenerator\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import cv2\n",
    "import skimage\n",
    "from lxml import etree\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "import gc\n",
    "import time\n",
    "import sys\n",
    "import getopt\n",
    "import pandas as pd\n",
    "import glob\n",
    "import tifffile as tif\n",
    "import staintools\n",
    "for i in package_list:\n",
    "    sys.path.append(i)\n",
    "# import StainNormalizer\n",
    "# from StainNormalizer import Normalizer\n",
    "import cupy as cp #用与cuda相符的版本\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239c65ea",
   "metadata": {},
   "source": [
    "## 函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c767e7f0",
   "metadata": {},
   "source": [
    "### 基本函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a89ecd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(training,validation,test,fold,labels,threshold=1000000,\n",
    "            absolute=False,remove_large_data_on=False,print_result = False):\n",
    "\n",
    "    def remove_large_data():\n",
    "        nonlocal training, validation, test, fold, labels,threshold\n",
    "        sum = training + validation + test\n",
    "        index = np.where(sum > threshold)\n",
    "        training = np.delete(training, index)\n",
    "        validation = np.delete(validation, index)\n",
    "        test = np.delete(test, index)\n",
    "        labels_copy = labels\n",
    "        labels = [labels_copy[x] for x in range(len(labels_copy)) if x not in np.array(index).tolist()[0]] # index：(array([3, 5, 6], dtype=int64),)，一个tuple，不能够用in直接判断，转成ndarray后再转成list以用in判断之\n",
    "        print('enter remove_large_data')\n",
    "        return training,validation,test,labels\n",
    "        \n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.title('dataset split')\n",
    "\n",
    "    if not absolute:\n",
    "        plt.yticks(np.linspace(0,1,11),labels=np.arange(0,101,10).tolist())\n",
    "        plt.ylabel('percentage')\n",
    "        sum = training+validation+test\n",
    "        bottom = training/sum\n",
    "        center = validation/sum\n",
    "        top = test/sum\n",
    "    else:\n",
    "        if remove_large_data_on:\n",
    "            bottom,center,top,labels = remove_large_data()\n",
    "        else:\n",
    "            bottom = training\n",
    "            center = validation\n",
    "            top = test\n",
    "        plt.yticks(np.linspace(0,np.max(bottom+center+top),10))\n",
    "        plt.ylabel('absolute amount')\n",
    "\n",
    "    N = bottom.size\n",
    "    ind = np.arange(N)\n",
    "    plt.xticks(np.arange(N),labels=labels,rotation=45)\n",
    "\n",
    "    width = 0.35  # 设置条形图一个长条的宽度\n",
    "    p1color = ['dodgerblue' if x else 'royalblue' for x in fold]\n",
    "    p2color = ['chartreuse' if x else 'limegreen'for x in fold]\n",
    "    p3color = ['gold' if x else 'orangered' for x in fold]\n",
    "    if print_result:\n",
    "        print(bottom,center,top,sum,p1color)\n",
    "    else:\n",
    "\n",
    "\n",
    "        p1 = plt.bar(ind, bottom, width, color=p1color)  \n",
    "        p2 = plt.bar(ind, center, width, bottom=bottom,color=p2color)  #在p1的基础上绘制，底部数据就是p1的数据\n",
    "        p3 = plt.bar(ind, top, width, bottom=bottom+center,color=p3color)    #在p1和p2的基础上绘制，底部数据就是p1和p2\n",
    "\n",
    "        plt.legend((p1[1], p2[1], p3[1]), ('training', 'validation', 'test'),loc = 3)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "class Timer():\n",
    "    def __init__(self,proc):\n",
    "        self._begin_time = None\n",
    "        self.proc = proc\n",
    "\n",
    "    def tic(self):\n",
    "        print(f'{self.proc} start!')\n",
    "        self._begin_time = time.perf_counter()\n",
    "\n",
    "    def toc(self):\n",
    "        print(f'{self.proc} finish!,consuming {time.perf_counter() - self._begin_time}')\n",
    "        return time.perf_counter() - self._begin_time\n",
    "\n",
    "def binary_conversion(var):\n",
    "    \"\"\"\n",
    "    二进制单位转换\n",
    "    :param var: 需要计算的变量，bytes值\n",
    "    :return: 单位转换后的变量，kb 或 mb\n",
    "    \"\"\"\n",
    "    var_size = sys.getsizeof(var)\n",
    "    assert isinstance(var_size, int)\n",
    "    if var_size <= 1024:\n",
    "        return f'占用 {round(var_size / 1024, 2)} KB内存'\n",
    "    else:\n",
    "        return f'占用 {round(var_size / (1024 ** 2), 2)} MB内存'\n",
    "    \n",
    "def show_info(show_values = False,**kws):\n",
    "    length = 'no length'\n",
    "    keys = 'not a dict'\n",
    "    values = 'not a dict'\n",
    "    shape = 'not a ndarray'\n",
    "    size = 'not a ndarray'\n",
    "    for key,x in kws.items():\n",
    "        if hasattr(x,'__len__'):\n",
    "            length = len(x)\n",
    "        if isinstance(x,dict):\n",
    "            keys = x.keys()\n",
    "            values = x.values()\n",
    "        if type(x) is np.ndarray or type(x) is cp.ndarray:\n",
    "            shape = x.shape\n",
    "            size = x.size\n",
    "        print(key)\n",
    "        print(f'allocated memory:{binary_conversion(x)}')\n",
    "        print(f'\\ntype:{type(x)} \\nlen:{length}\\nshape:{shape}\\nsize:{size}\\nkeys:{keys}\\noriginal info:{x}\\n')\n",
    "        if show_values:\n",
    "            print(f'\\nvalues:{values}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9295c8",
   "metadata": {},
   "source": [
    "### 图片可视化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c115eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_or_not(x,pr = False):  #只要有一个元素不为0则不为0\n",
    "    if type(x) is not np.ndarray:\n",
    "        x = np.array(x)\n",
    "    if pr:\n",
    "        if x.any():\n",
    "            print('not all 0')\n",
    "        else:\n",
    "            print('all 0')\n",
    "    return x.any()\n",
    "\n",
    "def show_dzg_info(dzg):\n",
    "    print(f'level count:{dzg.level_count}')\n",
    "    print(f'tile arrangement of last 3 level{dzg.level_tiles[-4:-1]}\\ndimensions of each tile at last 3 level:{dzg.level_dimensions[-4:-1]}')\n",
    "\n",
    "def pop_tile(dzg,level,save = False):\n",
    "    row,col = dzg.level_tiles[level]\n",
    "    saved = []\n",
    "    if level<0:\n",
    "        level = dzg.level_count + level\n",
    "    for i in range(row):\n",
    "        for j in range(col):\n",
    "            if null_or_not(dzg.get_tile(level,(i,j))):\n",
    "                saved.append((i,j))\n",
    "                if not save:\n",
    "                    print((i,j))\n",
    "    if save:\n",
    "        return saved\n",
    "\n",
    "def pixel_255(image,point = False,threshold = False):\n",
    "    if type(image) is not np.ndarray:\n",
    "        image = np.array(image)\n",
    "        if point:\n",
    "            image[image==0] = 255\n",
    "        if threshold:\n",
    "            image[image>threshold] = 255 \n",
    "        return Image.fromarray(image)\n",
    "    else:\n",
    "        if point:\n",
    "            image[image==0] = 255\n",
    "        if threshold:\n",
    "            image[image>threshold] = 255 \n",
    "        return image\n",
    "\n",
    "#通过cv显示图片\n",
    "def imgshow(img_path):\n",
    "    tiff = cv2.imread(img_path)\n",
    "    plt.imshow(Image.fromarray(tiff))\n",
    "\n",
    "#查看tiff文件path、info及图片\n",
    "def tiff_checker(tiff_path):\n",
    "    show_info(tiff_path = tiff_path)\n",
    "    tif.imshow(tif.imread(tiff_path))\n",
    "\n",
    "#同时展示多张图片\n",
    "def ploting(rows,cols,figseq,\n",
    "            figsize=(20,20),fontdict={'size':20},title = []):\n",
    "    #figseq是一个4维的ndarray\n",
    "    #rows,cols是展示图片的行/列数\n",
    "    fig,axes = plt.subplots(rows,cols,figsize=figsize)\n",
    "    fontdict = fontdict\n",
    "    if rows != 1:\n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                if title:\n",
    "                    axes[i,j].set_title(title[i*cols+j])\n",
    "                else:\n",
    "                    axes[i,j].set_title(f'{i}_{j}')\n",
    "                axes[i,j].imshow(figseq[i*cols+j])\n",
    "    else:\n",
    "        for j in range(cols):\n",
    "            if title:\n",
    "                axes[j].set_title(title[j])\n",
    "            else:\n",
    "                axes[j].set_title(f'{j}')\n",
    "            axes[j].imshow(figseq[j])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965e1f70",
   "metadata": {},
   "source": [
    "### patch extraction 函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8721466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slide(slide_path):\n",
    "    slide = openslide.OpenSlide(slide_path)\n",
    "    return slide\n",
    "# 提高亮度，处理异常像素点的函数\n",
    "def normalize_dynamic_range(image, percentile = 95):\n",
    "    \"\"\"\n",
    "    Normalize the dynamic range of an RGB image to 0~255. If the dynamic ranges of patches \n",
    "    from a dataset differ, apply this function before feeding images to VahadaneNormalizer,\n",
    "    e.g. hema slides.\n",
    "    :param image: A RGB image in np.ndarray with the shape [..., 3].\n",
    "    :param percentile: Percentile to get the max value.\n",
    "    \"\"\"\n",
    "    max_rgb = []\n",
    "    for i in range(3):\n",
    "        value_max = np.percentile(image[..., i], percentile)\n",
    "        max_rgb.append(value_max)\n",
    "    max_rgb = np.array(max_rgb)\n",
    "\n",
    "    new_image = (np.minimum(image.astype(np.float32) * (255.0 / max_rgb), 255.0)).astype(np.uint8)\n",
    "    \n",
    "    return new_image\n",
    "\n",
    "# 定义过滤白色的函数\n",
    "def filter_blank(image, threshold = 80):\n",
    "    image_lab = skimage.color.rgb2lab(np.array(image))\n",
    "    image_mask = np.zeros(image.shape).astype(np.uint8)\n",
    "    image_mask[np.where(image_lab[:, :, 0] < threshold)] = 1\n",
    "    image_filter = np.multiply(image, image_mask)\n",
    "    percent = ((image_filter != np.array([0,0,0])).astype(float).sum(axis=2) != 0).sum() / (image_filter.shape[0]**2)\n",
    "\n",
    "    return percent\n",
    "\n",
    "#@jit(nopython=True)\n",
    "def AnnotationParser(path):\n",
    "    assert Path(path).exists(), \"This annotation file does not exist.\"\n",
    "    tree = etree.parse(path)\n",
    "    annotations = tree.xpath(\"/ASAP_Annotations/Annotations/Annotation\")\n",
    "    annotation_groups = tree.xpath(\"/ASAP_Annotations/AnnotationGroups/Group\")\n",
    "    classes = [group.attrib[\"Name\"] for group in annotation_groups]\n",
    "   # @jit(nopython=True)\n",
    "    def read_mask_coord(cls):\n",
    "        for annotation in annotations:\n",
    "            if annotation.attrib[\"PartOfGroup\"] == cls:\n",
    "                contour = []\n",
    "                for coord in annotation.xpath(\"Coordinates/Coordinate\"):\n",
    "                    x = np.float(coord.attrib[\"X\"])\n",
    "                    y = np.float(coord.attrib[\"Y\"])\n",
    "                    contour.append([round(float(x)),round(float(y))])\n",
    "                #mask_coords[cls].extend(contour)\n",
    "                mask_coords[cls].append(contour)\n",
    "    #@jit(nopython=True)\n",
    "    def read_mask_coords(classes):\n",
    "        for cls in classes:\n",
    "            read_mask_coord(cls)\n",
    "        return mask_coords            \n",
    "    mask_coords = {}\n",
    "    for cls in classes:\n",
    "        mask_coords[cls] = []\n",
    "    mask_coords = read_mask_coords(classes)\n",
    "    return mask_coords,classes\n",
    "\n",
    "\n",
    "def Annotation(slide,path,save_path=None,rule=False,save=False):\n",
    "    #wsi_height = slide.wsi_height\n",
    "    #wsi_width = slide.wsi_width\n",
    "    wsi_width,wsi_height = slide.level_dimensions[0]\n",
    "    masks = {}\n",
    "    contours = {}\n",
    "    mask_coords, classes = AnnotationParser(path)\n",
    "    \n",
    "    def base_mask(cls,wsi_height,wsi_width):\n",
    "        masks[cls] = np.zeros((wsi_height,wsi_width),dtype=np.uint8)\n",
    "    def base_masks(wsi_height,wsi_width):\n",
    "        for cls in classes:\n",
    "            base_mask(cls,wsi_height,wsi_width)\n",
    "        return masks\n",
    "    \n",
    "    def main_masks(classes,mask_coords,masks):\n",
    "        for cls in classes:\n",
    "            contours = np.array(mask_coords[cls])\n",
    "            #contours = mask_coords[cls]\n",
    "            for contour in contours:\n",
    "                #print(f\"cls:{cls},\\ncontour:{contour},\\ntype:{type(contour)}\")\n",
    "                masks[cls] = cv2.drawContours(masks[cls],[np.int32(contour)],0,True,thickness=cv2.FILLED)\n",
    "        return masks\n",
    "   # def make_masks()\n",
    "    def export_mask(save_path,cls):\n",
    "        assert Path(save_path).is_dir()\n",
    "        cv2.imwrite(str(Path(save_path)/\"{}.tiff\".format(cls)),masks[cls],(cv2.IMWRITE_PXM_BINARY,1))\n",
    "    def export_masks(save_path):\n",
    "        for cls in masks.keys():\n",
    "            export_mask(save_path,cls)\n",
    "    def exclude_masks(masks,rule,classes):\n",
    "        #masks_exclude = masks.copy()\n",
    "        masks_exclude = masks\n",
    "        for cls in classes:\n",
    "            for exclude in rule[cls][\"excludes\"]:\n",
    "                if exclude in masks:\n",
    "                    overlap_area = cv2.bitwise_and(masks[cls],masks[exclude])\n",
    "                    masks_exclude[cls] = cv2.bitwise_xor(masks[cls],overlap_area)\n",
    "        #masks = masks_exclude\n",
    "        return masks_exclude\n",
    "                    \n",
    "    masks = base_masks(wsi_height,wsi_width)\n",
    "    masks = main_masks(classes,mask_coords,masks)\n",
    "    if rule:\n",
    "        classes = list(set(classes) & set(rule.keys()))\n",
    "        masks = exclude_masks(masks,rule,classes)\n",
    "        #include_masks(rule)\n",
    "        #exclude_masks(rule)\n",
    "    if save:\n",
    "        export_masks(save_path)\n",
    "    if \"artificial\" not in classes:\n",
    "        masks[\"artificial\"] = np.zeros((wsi_height,wsi_width),dtype=np.uint8)\n",
    "    if \"necrosis\" not in classes:\n",
    "        masks[\"necrosis\"] = np.zeros((wsi_height,wsi_width),dtype=np.uint8)\n",
    "    if 'stroma' not in classes:\n",
    "        masks['stroma'] = np.zeros((wsi_height,wsi_width),dtype=np.uint8)\n",
    "    return masks\n",
    "\n",
    "def show_thumb_mask(mask,size=512):\n",
    "    #mask = masks[cls]\n",
    "    height, width = mask.shape\n",
    "    scale = max(size / height, size / width)\n",
    "    mask_resized = cv2.resize(mask, dsize=None, fx=scale, fy=scale)\n",
    "    mask_scaled = mask_resized * 255\n",
    "    plt.imshow(mask_scaled)\n",
    "    return mask_scaled\n",
    "\n",
    "def get_mask_slide(masks):\n",
    "    tumor_slide = openslide.ImageSlide(Image.fromarray(masks['tumor']))\n",
    "    non_tumor_slide = openslide.ImageSlide(Image.fromarray(cv2.bitwise_not(masks['tumor'])-254))\n",
    "    #mark_slide = openslide.ImageSlide(Image.fromarray(masks[\"mark\"])) ## get tile_masked dont need mark and arti mask\n",
    "    #arti_slide = openslide.ImageSlide(Image.fromarray(masks[\"artifact\"]))\n",
    "    return (tumor_slide,non_tumor_slide)\n",
    "\n",
    "def get_tiles(slide,tumor_slide,tile_size=512,overlap=False,limit_bounds=False,slide_tile = False):\n",
    "    slide_tiles = DeepZoomGenerator(slide,tile_size,overlap=overlap,limit_bounds=limit_bounds)\n",
    "    tumor_tiles = DeepZoomGenerator(tumor_slide,tile_size,overlap=overlap,limit_bounds=limit_bounds)\n",
    "    #mark_tiles = DeepZoomGenerator(mark_slide,tile_size,overlap=overlap,limit_bounds=limit_bounds)\n",
    "    #arti_tiles = DeepZoomGenerator(arti_slide,tile_size,overlap=overlap,limit_bounds=limit_bounds)\n",
    "    if slide_tile:\n",
    "        return slide_tiles,tumor_tiles\n",
    "    else:\n",
    "        return tumor_tiles\n",
    "#@njit\n",
    "def remove_arti_and_mask(slide_tile,tumor_tile):\n",
    "    #mark_tile = np.where(mark_tile==0,1,0)\n",
    "    #arti_tile = np.where(arti_tile==0,1,0)\n",
    "    #assert slide_tile.shape\n",
    "    #slide_tile = np.array(slide_tile)\n",
    "    #tumor_tile = np.array(tumor_tile)\n",
    "    x = slide_tile.shape\n",
    "    if not x == tumor_tile.shape:\n",
    "        tumor_tile = tumor_tile[:x[0],:x[1],:]\n",
    "    #if not mark_tile.shape == x:\n",
    "       # mark_tile = mark_tile[:x[0],:x[1],:]\n",
    "    #if not arti_tile.shape == x:\n",
    "       # arti_tile = arti_tile[:x[0],:x[1],:]\n",
    "    #tile = np.multiply(np.multiply(slide_tile,mark_tile),arti_tile)\n",
    "    #if tile[np.where(tile==np.array([0,0,0]))].shape!=(0,):\n",
    "        #tile[np.where(tile==np.array([0,0,0]))]= fill\n",
    "    #tile[np.where(tile==np.array([0,0,0]))] = fill # fill blank may cause color torsion\n",
    "    tile_masked= np.multiply(slide_tile,tumor_tile)\n",
    "    #tile = Image.fromarray(np.uint8(tile))\n",
    "    #assert tile.size==(512,512),f\"wrong shape:{tile.size}\"\n",
    "    return slide_tile,tile_masked\n",
    "def get_tile_masked(slide_tile,tumor_tile): ####version_update: To save tile_masked, use this function\n",
    "    x = slide_tile.shape\n",
    "    y = tumor_tile.shape\n",
    "    if not x == y:\n",
    "        h = np.min([x[0],y[0]])\n",
    "        w = np.min([x[1],y[1]])\n",
    "        tumor_tile = tumor_tile[:h,:w,:]\n",
    "        slide_tile = slide_tile[:h,:w,:]\n",
    "    tile_masked = np.multiply(slide_tile,tumor_tile)\n",
    "    percent = np.mean(tumor_tile)\n",
    "    tile_masked[np.all(tile_masked==0)]=255\n",
    "    return tile_masked,percent\n",
    "def filtered_same(img):### modify to purely count tumor tile\n",
    "    percent = ((img[:,:,0]==img[:,:,1]).astype(float) *(img[:,:,0]==img[:,:,2]).astype(float)).sum()/(img.shape[0]**2)\n",
    "    return percent\n",
    "def filtered(tile):\n",
    "    tolerance = np.array([230,230,230])\n",
    "    #tile_1 = tile.copy()\n",
    "    tile[np.all(tile>tolerance,axis=2)]=0\n",
    "    percent = ((tile != np.array([0,0,0])).astype(float).sum(axis=2)!=0).sum()/(tile.shape[0]**2)\n",
    "    return percent\n",
    "def filtered_cv(img):\n",
    "    #tolerance = np.array([230,230,230])\n",
    "    #tile_1 = tile.copy()\n",
    "    tile = np.copy(img).astype(np.uint8)\n",
    "    gray = cv2.cvtColor(tile,cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray,(5,5),0)\n",
    "    ret,_ = cv2.threshold(blur,0,1,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    tile[np.all(tile>ret,axis=2)] = 0\n",
    "    percent = ((tile != np.array([0,0,0])).astype(float).sum(axis=2)!=0).sum()/(tile.shape[0]**2)\n",
    "    return percent\n",
    "\n",
    "def filter_blood(img):\n",
    "    ## lower mask(0-10)\n",
    "    img_hsv = cv2.cvtColor(img,cv2.COLOR_RGB2HSV)\n",
    "    lower_red = np.array([0,50,50])\n",
    "    upper_red = np.array([10,255,255])\n",
    "    mask0 = cv2.inRange(img_hsv, lower_red, upper_red)\n",
    "\n",
    "    # upper mask (170-180)\n",
    "    lower_red = np.array([170,50,50])\n",
    "    upper_red = np.array([180,255,255])\n",
    "    mask1 = cv2.inRange(img_hsv, lower_red, upper_red)\n",
    "\n",
    "    # join my masks\n",
    "    mask = mask0+mask1\n",
    "    percent = ((mask != 0)).sum()/mask.shape[0]**2\n",
    "    return percent\n",
    "#@jit(nopython=True)\n",
    "def extract_patches(levels,scales,tile_path,slide_tiles,tumor_tiles,tumor=True):\n",
    "    \n",
    "    for i,level in enumerate(levels):\n",
    "        if tumor:\n",
    "            print(f'processing ---level {scales[i]},tumor tiles')\n",
    "        else:\n",
    "            print(f'processing ---level {scales[i]},non-tumor tiles')\n",
    "        print(tile_path)\n",
    "        tiledir = Path(tile_path)/str(scales[i])\n",
    "        #print(f\"tile_dir creating--{tiledir}\")\n",
    "        \n",
    "        if not Path(tiledir).exists():\n",
    "            os.makedirs(tiledir)\n",
    "           # print(\"tile_dir created\")\n",
    "        assert slide_tiles.level_tiles[level] == tumor_tiles.level_tiles[level]\n",
    "        cols,rows = slide_tiles.level_tiles[level]\n",
    "        for row in range(rows):\n",
    "            for col in range(cols):\n",
    "                if tumor:\n",
    "                    tilename = os.path.join(tiledir,'%s_%d_%d.%s'%('T',col,row,\"tiff\"))\n",
    "                else:\n",
    "                    tilename = os.path.join(tiledir,'%s_%d_%d.%s'%('nonT',col,row,\"tiff\"))\n",
    "               # print(\"tile_name creating\")\n",
    "                if not Path(tilename).exists():\n",
    "                    slide_tile = np.array(slide_tiles.get_tile(level,(col,row)))\n",
    "                    tumor_tile = np.array(tumor_tiles.get_tile(level,(col,row)))\n",
    "\n",
    "                    #mark_tile = np.array(mark_tiles.get_tile(level,(col,row)))\n",
    "                    #arti_tile = np.array(arti_tiles.get_tile(level,(col,row)))\n",
    "                    #print(\"tiles are processing\")\n",
    "                    #tile,tile_masked = remove_arti_and_mask(slide_tile,tumor_tile,mark_tile,arti_tile)\n",
    "                    tile_masked,percent_2 = get_tile_masked(slide_tile,tumor_tile) # percent of annotated area       \n",
    "                   # tile_masked = np.multiply(slide_tile,mark_tile)\n",
    "                    percent_1 = filter_blank(tile_masked) # percent of tissue area\n",
    "                    #percent_2 = filtered_same(tile_masked)\n",
    "                    percent_3 = filter_blood(tile_masked)\n",
    "\n",
    "                    if all((percent_1 >= 0.75,percent_2 >= 0.75)):\n",
    "                       # Image.fromarray(np.uint8(tile)).save(tilename)\n",
    "                        Image.fromarray(np.uint8(tile_masked)).save(tilename)\n",
    "                        #print(\"saving tile\")\n",
    "                    else:\n",
    "                        pass\n",
    "        print(\"Done!\")\n",
    "    print(\"All levels processed!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9b19e4",
   "metadata": {},
   "source": [
    "### stain normalizer函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d5c2440",
   "metadata": {},
   "outputs": [],
   "source": [
    "#切割的图片大小大多为512，normalization将非512*512的去除，大约占比为10%\n",
    "def gen_normal_size(I_list,target_shape=(512,512,3)):\n",
    "    for i in I_list:\n",
    "        try:\n",
    "            tiff = tif.imread(i)\n",
    "            if tiff.shape == target_shape:\n",
    "                yield i\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "\n",
    "#normalizer类\n",
    "class HENormalizer:\n",
    "    def fit(self, target):\n",
    "        pass\n",
    "\n",
    "    def normalize(self, I, **kwargs):\n",
    "        raise Exception('Abstract method')\n",
    "\n",
    "\"\"\"\n",
    "Inspired by torchstain :\n",
    "Source code adapted from: https://github.com/schaugf/HEnorm_python;\n",
    "Original implementation: https://github.com/mitkovetta/staining-normalization\n",
    "\"\"\"\n",
    "class Normalizer(HENormalizer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.HERef = cp.array([[0.5626, 0.2159],\n",
    "                          [0.7201, 0.8012],\n",
    "                          [0.4062, 0.5581]])\n",
    "        self.maxCRef = cp.array([1.9705, 1.0308])\n",
    "\n",
    "    def __convert_rgb2od(self, I, Io=240, beta=0.15):\n",
    "        # calculate optical density\n",
    "        OD = -cp.log((I.astype(cp.float32)+1)/Io)\n",
    "\n",
    "        # remove transparent pixels\n",
    "        ODhat = OD[~cp.any(OD < beta, axis=1)]\n",
    "\n",
    "        return OD, ODhat\n",
    "\n",
    "    def __find_HE(self, ODhat, eigvecs, alpha):\n",
    "        #project on the plane spanned by the eigenvectors corresponding to the two\n",
    "        # largest eigenvalues\n",
    "        That = ODhat.dot(eigvecs[:,1:3])\n",
    "\n",
    "        phi = cp.arctan2(That[:,1],That[:,0])\n",
    "\n",
    "        minPhi = cp.percentile(phi, alpha)\n",
    "        maxPhi = cp.percentile(phi, 100-alpha)\n",
    "\n",
    "        vMin = eigvecs[:,1:3].dot(cp.array([(cp.cos(minPhi), cp.sin(minPhi))]).T)\n",
    "        vMax = eigvecs[:,1:3].dot(cp.array([(cp.cos(maxPhi), cp.sin(maxPhi))]).T)\n",
    "\n",
    "        # a heuristic to make the vector corresponding to hematoxylin first and the\n",
    "        # one corresponding to eosin second\n",
    "        if vMin[0] > vMax[0]:\n",
    "            HE = cp.array((vMin[:,0], vMax[:,0])).T\n",
    "        else:\n",
    "            HE = cp.array((vMax[:,0], vMin[:,0])).T\n",
    "\n",
    "        return HE\n",
    "\n",
    "    def __find_concentration(self, OD, HE):\n",
    "        # rows correspond to channels (RGB), columns to OD values\n",
    "        Y = cp.reshape(OD, (-1, 3)).T\n",
    "\n",
    "        # determine concentrations of the individual stains\n",
    "        C = cp.linalg.lstsq(HE, Y, rcond=None)[0]\n",
    "\n",
    "        return C\n",
    "\n",
    "    def __compute_matrices(self, I, Io, alpha, beta):\n",
    "        I = I.reshape((-1,3))\n",
    "\n",
    "        OD, ODhat = self.__convert_rgb2od(I, Io=Io, beta=beta)\n",
    "\n",
    "        # compute eigenvectors\n",
    "        _, eigvecs = cp.linalg.eigh(cp.cov(ODhat.T))\n",
    "\n",
    "        HE = self.__find_HE(ODhat, eigvecs, alpha)\n",
    "\n",
    "        C = self.__find_concentration(OD, HE)\n",
    "\n",
    "        # normalize stain concentrations\n",
    "        maxC = cp.array([cp.percentile(C[0,:], 99), cp.percentile(C[1,:],99)])\n",
    "\n",
    "        return HE, C, maxC\n",
    "\n",
    "    def fit(self, I, Io=240, alpha=1, beta=0.15):\n",
    "        I = cp.asarray(I)\n",
    "        HE, _, maxC = self.__compute_matrices(I, Io, alpha, beta)\n",
    "\n",
    "        self.HERef = HE\n",
    "        self.maxCRef = maxC\n",
    "\n",
    "    def normalize(self, I, Io=240, alpha=1, beta=0.15):\n",
    "        ''' Normalize staining appearence of H&E stained images\n",
    "        Example use:\n",
    "            see test.py\n",
    "        Input:\n",
    "            I: RGB input image\n",
    "            Io: (optional) transmitted light intensity\n",
    "        Output:\n",
    "            Inorm: normalized image\n",
    "            H: hematoxylin image\n",
    "            E: eosin image\n",
    "        Reference:\n",
    "            A method for normalizing histology slides for quantitative analysis. M.\n",
    "            Macenko et al., ISBI 2009\n",
    "        '''\n",
    "       # I = cp.asarray(I)\n",
    "        batch,h, w, c = I.shape\n",
    "        I = I.reshape((-1,3))\n",
    "\n",
    "        HE, C, maxC = self.__compute_matrices(I, Io, alpha, beta)\n",
    "\n",
    "        maxC = cp.divide(maxC, self.maxCRef)\n",
    "        C2 = cp.divide(C, maxC[:, cp.newaxis])\n",
    "\n",
    "        # recreate the image using reference mixing matrix\n",
    "        Inorm = cp.multiply(Io, cp.exp(-self.HERef.dot(C2)))\n",
    "        Inorm[Inorm > 255] = 255\n",
    "        Inorm = cp.reshape(Inorm.T, (batch,h, w, c)).astype(cp.uint8)\n",
    "\n",
    "\n",
    "\n",
    "        return Inorm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55f1b54-fbcb-42d2-b959-9355c3b57760",
   "metadata": {},
   "source": [
    "## 试一下openslide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20392fc1-1073-4180-b74e-64ec5b983a58",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'openslide' has no attribute 'slide_info'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m slide \u001b[38;5;241m=\u001b[39m openslide\u001b[38;5;241m.\u001b[39mOpenSlide(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/mnt/wangyh/TCGA_svs/007a342d-6d2d-472b-afd6-2978c3e588a2/TCGA-GU-A762-01Z-00-DX1.F01B133E-3744-4430-9752-FDD25EEF58A3.svs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mopenslide\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslide_info\u001b[49m(slide)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'openslide' has no attribute 'slide_info'"
     ]
    }
   ],
   "source": [
    "slide = openslide.OpenSlide('/mnt/wangyh/TCGA_svs/007a342d-6d2d-472b-afd6-2978c3e588a2/TCGA-GU-A762-01Z-00-DX1.F01B133E-3744-4430-9752-FDD25EEF58A3.svs')\n",
    "openslide.slide_info(slide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00acfa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training = np.array([407*0.9,167,7*3253.7,549,559,6953,65673,477.1,93])\n",
    "# validation = np.array([40.7,12,2*3253.7,2501,283,1631,14317,28.8,23])\n",
    "# test = np.array([16,0,1*3253.7,0,111,330,16862,0.126,64])\n",
    "# fold = [True,False,False,False,False,False,False,False,False]\n",
    "# labels = ['Eur Urol,2020','Ebiomedicine,2021','Nature,2021','Lancet Digit Health,2020','BMC medicine,2021','Lancet Oncol,2020','Neuro Oncol,2020','Ebiomedicine,2020','JAMA NetW 2019']\n",
    "\n",
    "# draw(training,validation,test,fold,labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f65d5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw(training,validation,test,fold,labels,\n",
    "#     threshold=1000,\n",
    "#     absolute=True,remove_large_data_on=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cd0d00-076e-4771-8f56-8940de681151",
   "metadata": {},
   "source": [
    "## 查看TCGA_svs文件夹内文件是否被全部上传"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc05ed19-8e85-4fae-9abb-b8c3539f49df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORM = np.random.randint(0,255,(256,256,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e9c7e4d-f3fd-4e4d-8ec7-3dca61fa64cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uploaded = os.listdir('./TCGA_svs/TCGA_bladder')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32a98c4-2a40-4fb5-aeb8-4aa532ba4b29",
   "metadata": {},
   "source": [
    "## 基本参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26a13d20-730c-4d6e-a26e-e9635da7dff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OVERLAP =0\n",
    "# LIMIT = False\n",
    "# rule =  {\"tumor\":{\"excludes\":[\"artificial\",\"stroma\",\"necrosis\"]},\n",
    "#         'stroma':{\"excludes\":['artificial','necrosis']}}\n",
    "# scales = ['5X','10X','20X','40X']\n",
    "# TILE_SIZE = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a25e82e-e3bd-44df-90b7-aa7f47246bb5",
   "metadata": {},
   "source": [
    "## 测试svs_paths是否work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15ca7f7e-7447-49c3-aa04-570f2ba1a72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# patch_path = f\"/home/wangyh/uro_biomarker/patho_AI/TCGA_patches/\"\n",
    "\n",
    "df = pd.read_csv('./config/full.csv')\n",
    "\n",
    "# #得到最后用于下一步的所有图像路径，labels\n",
    "# # svs_paths = df['svs_paths']\n",
    "labels = df['TMB_H/L']\n",
    "uuid = df['dir_uuid']\n",
    "\n",
    "# #得到单个图像路径\n",
    "# # unextracted_path = [\n",
    "# #     '/mnt/wangyh/TCGA_svs/f4ca3ddd-dc53-4ab0-b55b-942603b64e57/TCGA-BT-A20Q-01Z-00-DX1.BFF3D35C-CB0C-49C3-8D35-D5C84E133B49.svs'\n",
    "# # ]\n",
    "# # labels = ['L']\n",
    "\n",
    "# #获取单个图像路径、xml、label\n",
    "# svs = glob.glob('/mnt/wangyh/TCGA_svs/1fa739c1-75f2-433b-91c7-f743bdf0fce0/*.svs')[0]\n",
    "# label = 'H'\n",
    "# xml_path = Path(svs).with_suffix('.xml')\n",
    "\n",
    "# #提取用于文件夹命名的case_name（就是uuid）\n",
    "# case_name = '1fa739c1-75f2-433b-91c7-f743bdf0fce0'\n",
    "# # #得到放tile的文件夹路径\n",
    "# tile_path = Path(patch_path)/label/case_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2417041d-a313-438a-9e3f-0ead96e22bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10):\n",
    "#     print(f'uuid:{uuid[i*39]},label:{labels[i*39]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fba467c6-6fc6-4fc5-8f9b-256a8d22173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#取相同文件夹下的xml文件\n",
    "# Path(svs).with_suffix('.xml')\n",
    "# glob.glob(f'{str(Path(svs).parent)}/*.xml') #相同效果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4537efa8-2507-4c1b-b87f-4f1671d60288",
   "metadata": {},
   "source": [
    "## 玻片提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bad9536-ef9d-4446-b5af-ac165be128d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slide = get_slide(svs)\n",
    "# extracted_case = []\n",
    "# un_extracted_case = []\n",
    "# try:\n",
    "#     masks = Annotation(slide,path=str(xml_path))\n",
    "#     print(f\"masks groups includes :{list(masks.keys())}\")\n",
    "#     tumor_XOR = get_mask_slide(masks)    #返回一个tuple，第一个是tumor_slide，第二个是non_tumor_slide，两个都是Imageslide\n",
    "#     #获得dzg对象                                      \n",
    "#     tumor_tiles = get_tiles(slide,tumor_XOR[0],tile_size=TILE_SIZE,overlap=OVERLAP,limit_bounds=LIMIT)\n",
    "#     slide_tiles,non_tumor_tiles = get_tiles(slide,tumor_XOR[1],tile_size=TILE_SIZE,overlap=OVERLAP,limit_bounds=LIMIT,slide_tile\n",
    "#                                             = True)\n",
    "\n",
    "#     del slide\n",
    "#     del masks\n",
    "#     del tumor_XOR\n",
    "#     gc.collect()\n",
    "#     level_count = slide_tiles.level_count\n",
    "#     #fill = int(np.array(slide_tiles.get_tile(level_count-1,(0,0))).mean())\n",
    "#     levels=[level_count-4,level_count-3,level_count-2,level_count-1]\n",
    "#     try:\n",
    "#         extract_patches(levels,scales,tile_path,slide_tiles,tumor_tiles)\n",
    "#         extract_patches(levels,scales,tile_path,slide_tiles,non_tumor_tiles,tumor=False)\n",
    "#         extracted_case.append(svs)\n",
    "#     except Exception as e:\n",
    "#         un_extracted_case.append(svs)\n",
    "#         print(\"something is wrong when extracting\")\n",
    "#         print(\"ERROR!\",e)\n",
    "# except Exception as e:\n",
    "#     print(\"something is wrong when parsing\")\n",
    "#     print(\"ERROR!\",e)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c3bb19-fd6c-45b7-80a6-c8be132da95d",
   "metadata": {},
   "source": [
    "## 将完整的svs_path合并到csv里保证一一对应"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5ef455d-3451-4cc4-9407-fd7953fa3e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('./config/TMB_uuid.csv')\n",
    "# uuid = df['dir_uuid']\n",
    "# def svs_path_generator(uuid):\n",
    "#     return glob.glob(f\"/mnt/wangyh/TCGA_svs/{uuid}/*.svs\")[0]\n",
    "# svs_paths = uuid.apply(svs_path_generator)\n",
    "# # svs_paths = [glob.glob(f\"{working_dir}/TCGA_svs/TCGA_bladder/{x}/*.svs\")[0] for x in uuid]\n",
    "# #改一下实现方法\n",
    "# svs_labels = df[\"TMB_H/L\"]\n",
    "# df['svs_paths']=svs_paths\n",
    "\n",
    "\n",
    "# df.to_csv('full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af095cf9-a8ed-4d9c-a09e-360443d05865",
   "metadata": {},
   "source": [
    "## 试一下tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61828a9c-23c7-4787-ad43-8dc743513873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # os.getcwd()\n",
    "# path = '/home/wangyh/uro_biomarker/patho_AI/TCGA_patches/H/1fa739c1-75f2-433b-91c7-f743bdf0fce0/5X/'\n",
    "# files = glob.glob(path + 'nonT*.tiff')\n",
    "# tiff_checker(files[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ab566e-3733-4474-adf1-19d388b225d3",
   "metadata": {},
   "source": [
    "## Color Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bdc972-a955-4733-903a-475612441785",
   "metadata": {},
   "source": [
    "### template & target path/files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "564ffd54-69a6-4a4d-bec8-7038619aaaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# template_paths = [i for i in gen_normal_size(glob.glob('/mnt/wangyh/TCGA_patches/H/c7bcb827-9da0-4b07-8065-3ce01befec13/40X/*.tiff'))]\n",
    "# template_file = pixel_255(tif.TiffSequence(template_paths[:100]).asarray(),point=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90bfe3a4-7b78-4cf1-ac9c-5be6130dda6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_paths = [i for i in gen_normal_size(glob.glob('/mnt/wangyh/TCGA_patches/L/bff29d20-3a8f-4a5d-a2de-0e142390551d/5X/*.tiff'))]\n",
    "# target_tiles = tif.imread(target_paths[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f237b29e-9b19-457a-b5df-b72989701a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = tif.imread('/mnt/wangyh/TCGA_patches/L/1f24af21-9bb4-409f-8bbc-5a0e56d777ab/40X/nonT_222_59.tiff')\n",
    "# show_info(t=t)\n",
    "# cp.asarray(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc87da9-0b02-4f4c-824f-04fb18f6a2c0",
   "metadata": {},
   "source": [
    "### stain normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1795036-0735-4e63-8612-7361c6efa01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SN_normalizer = Normalizer()\n",
    "# SN_normalizer.fit(template_file[11])\n",
    "# # target_tile = cp.asarray(target_tiles[:50])\n",
    "# target_tile = cp.asarray(tif.imread('/mnt/wangyh/TCGA_patches/L/1f24af21-9bb4-409f-8bbc-5a0e56d777ab/40X/nonT_222_59.tiff').reshape(1,512,512,3))\n",
    "# SN_normed = SN_normalizer.normalize(target_tile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92953318-9c9b-48cf-bcf5-89a23be0001d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploting(1,3,figseq=[target_tile[1].get(),SN_normed[1].get(),template_file[11]],title=['unnormed','normed','template'])\n",
    "#  ploting(1,3,figseq=[target_tile.get(),SN_normed.get(),template_file[11]],title=['unnormed','normed','template'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "decc8bec-3c32-4c76-a52f-9a267c14f9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,axes = plt.subplots(1,3,figsize=(30,10))\n",
    "\n",
    "# fontdict = {'size':20}\n",
    "\n",
    "# ax1 = axes[0]\n",
    "# ax1.set_title('unnormed',fontdict=fontdict)\n",
    "# ax1.imshow(target_tile[1].get())\n",
    "\n",
    "# ax2 = axes[1]\n",
    "# ax2.set_title('normed',fontdict=fontdict)\n",
    "# ax2.imshow(normed[1].get()) #这里遇到cp.array在imshow中反应很慢的问题，使用.get（）或通过cp.asnumpy()将数组转化为np.array后进行展示\n",
    "\n",
    "# ax3 = axes[2]\n",
    "# ax3.set_title('template',fontdict = fontdict)\n",
    "# ax3.imshow(template_file[27])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaee727-ea86-4434-b2b3-90b139b0f859",
   "metadata": {},
   "source": [
    "### staintools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e521343-066d-42e0-bdd1-223f64894c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read data\n",
    "# ST_template = staintools.read_image(template_paths[11])\n",
    "# ST_target = staintools.read_image(target_paths[1])\n",
    "\n",
    "# # Standardize brightness (optional, can improve the tissue mask calculation)\n",
    "# ST_template = staintools.LuminosityStandardizer.standardize(pixel_255(ST_template,point=True))\n",
    "# ST_target = staintools.LuminosityStandardizer.standardize(ST_target)\n",
    "\n",
    "# # # Stain normalize\n",
    "# V_normalizer = staintools.StainNormalizer(method='vahadane')\n",
    "# V_normalizer.fit(ST_template)\n",
    "# V_transformed = V_normalizer.transform(ST_target)\n",
    "\n",
    "# M_normalizer = staintools.StainNormalizer(method='Macenko')\n",
    "# M_normalizer.fit(ST_template)\n",
    "# M_transformed = M_normalizer.transform(ST_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95cf6447-3d06-41fe-beb0-dba07436ac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploting(1,4,figsize=(30,10),figseq=[ST_target,V_transformed,M_transformed,ST_target],title=['unnormed','V_normed','M_normed','template'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e59f89d-5370-49b2-8d8a-feb724ea604b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figseq = []\n",
    "# title = []\n",
    "# for i in range(25):\n",
    "#     figseq.append(staintools.read_image(template_paths[i]))\n",
    "#     title.append(i)\n",
    "# ploting(5,5,figseq=figseq,title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b7c979-d09a-4347-ba8f-6a05ed52b763",
   "metadata": {},
   "source": [
    "### 验证两个工具CN效果是否相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d36176c6-d4fc-4c07-899b-495b8d99ec41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformed == target_tile[1].get()  #由于staintools进行了luminostandardization两者不同\n",
    "# show_info(tar= target_tile[1],trans=transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e5f92b-cebc-4d0e-8820-6cf152fa497c",
   "metadata": {},
   "source": [
    "### 找到比较好的template,用staintools做光标准化后挑一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01d0437e-563c-49d5-ae82-89def01020a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploting(5,5,template_files[25:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6376111f-f530-4d3f-bee0-fa48da189c30",
   "metadata": {},
   "source": [
    "## 设置CN的路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81566b9e-66d4-444d-8024-a820e9ab04fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cases \u001b[38;5;241m=\u001b[39m \u001b[43mglob\u001b[49m\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/mnt/wangyh/TCGA_patches/*/*/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m cn_path_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/wangyh/uro_biomarker/patho_AI/CN_test/\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'glob' is not defined"
     ]
    }
   ],
   "source": [
    "cases = glob.glob(f\"/mnt/wangyh/TCGA_patches/*/*/\")\n",
    "cn_path_test = '/home/wangyh/uro_biomarker/patho_AI/CN_test/'\n",
    "# case = Path(cases[0])\n",
    "# mag_40 = list(case.glob('*'))[0].name\n",
    "# tiles = list(case.rglob('*/*'))\n",
    "# tile = tiles[0]\n",
    "# tile_name = str(tile).replace('/mnt/wangyh/TCGA_patches/',cn_path_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6c8c11-2308-4d55-941e-ea93404a1dee",
   "metadata": {},
   "source": [
    "## COLOR NORMALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b608b92-4051-43ed-ac3b-a143f84c3ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "cases_select = cases[:10]\n",
    "\n",
    "mempool = cp.get_default_memory_pool()\n",
    "pinned_mempool = cp.get_default_pinned_memory_pool()\n",
    "\n",
    "template_paths = [i for i in gen_normal_size(glob.glob('/mnt/wangyh/TCGA_patches/H/c7bcb827-9da0-4b07-8065-3ce01befec13/40X/*.tiff'))]\n",
    "template_file = pixel_255(tif.TiffSequence(template_paths[:100]).asarray(),point=True)\n",
    "\n",
    "'''\n",
    "use staintools\n",
    "'''\n",
    "# # Read data\n",
    "# target = staintools.read_image(template_paths[27])\n",
    "\n",
    "# # Standardize brightness (optional, can improve the tissue mask calculation)\n",
    "# target = staintools.LuminosityStandardizer.standardize(pixel_255(target,point=True))\n",
    "\n",
    "# # Stain normalize initializatino\n",
    "# normalizer = staintools.StainNormalizer(method='vahadane')\n",
    "# normalizer.fit(target)\n",
    "\n",
    "'''\n",
    "use stain_normalizer\n",
    "'''\n",
    "SN_normalizer = Normalizer()\n",
    "SN_normalizer.fit(template_file[11])\n",
    "# target_tile = cp.asarray(target_tiles[:50])\n",
    "# SN_normed = SN_normalizer.normalize(target_tile)\n",
    "\n",
    "\n",
    "unnorm_tiles = []\n",
    "\n",
    "print(len(cases_select))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27488f1c-34be-44ca-88fa-48f9cbec8a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "for case in tqdm(cases_select):\n",
    "#     label = Path(case).parent.name\n",
    "    tiles = list(Path(case).rglob(\"*/*\"))\n",
    "    print(len(tiles))\n",
    "    try:\n",
    "        for tile in tiles:\n",
    "            try:\n",
    "                tile_name = str(tile).replace('/mnt/wangyh/TCGA_patches/',cn_path_test)  #transformed tile的存放路径\n",
    "                if not Path(tile_name).exists():\n",
    "                    if not Path(tile_name).parent.exists():\n",
    "                        Path(tile_name).parent.mkdir(parents=True)\n",
    "                        \n",
    "                    tile_img = tif.imread(str(tile))  #读取to_transformed tile\n",
    "                    if tile_img.shape[0] != 512 or tile_img.shape[1] != 512:\n",
    "                        tile_img = Image.fromarray(np.uint8(tile_img)).resize((512,512),Image.ANTIALIAS)\n",
    "                        tile_img = np.asarray(tile_img)\n",
    "                    #tile_name = str(tile).replace\n",
    "                   # tile_img = tif.imread(str(tile))\n",
    "                    #print(tile_img)\n",
    "                    \n",
    "                    '''\n",
    "                    staintools\n",
    "                    '''\n",
    "#                     lum_stand_tile = staintools.LuminosityStandardizer.standardize(pixel_255(tile_img,point=True))\n",
    "#                     norm_imgs = normalizer.transform(lum_stand_tile)\n",
    "                    \n",
    "                    '''\n",
    "                    stain_normalizer\n",
    "                    '''\n",
    "                    tile_img = tile_img.reshape(1,512,512,3)\n",
    "                    imgs = cp.asarray(tile_img,dtype=cp.float64)\n",
    "                    norm_imgs= cp.asnumpy(SN_normalizer.normalize(I=imgs))\n",
    "                    norm_imgs = norm_imgs.reshape(512,512,3)\n",
    "                    tif.imsave(tile_name,norm_imgs)\n",
    "                   # Image.fromarray(np.uint8(norm_imgs)).save(tile_name)\n",
    "            except Exception as e:\n",
    "                    print(e)\n",
    "                    print(tile)\n",
    "                    unnorm_tiles.append(tile)\n",
    "            #norm_imgs = None\n",
    "            imgs = None\n",
    "            mempool.free_all_blocks() \n",
    "            pinned_mempool.free_all_blocks()\n",
    "            gc.collect() \n",
    "     \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(case) \n",
    "        continue\n",
    "np.save(f\"{cn_path_test}unnormed.npy\",np.asarray(unnorm_tiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b1bf647-5c44-4852-a056-f40947091387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/wangyh/uro_biomarker/patho_AI/CN_test/unnormed.npy'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn_path_test = '/home/wangyh/uro_biomarker/patho_AI/CN_test/'\n",
    "f\"{cn_path_test}unnormed.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37f20478-992e-4294-a9f8-14fe5fb31f09",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot load file containing pickled data when allow_pickle=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/wangyh/uro_biomarker/patho_AI/normed\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/patho_AI/lib/python3.8/site-packages/numpy/lib/npyio.py:445\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n\u001b[0;32m--> 445\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot load file containing pickled data \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    446\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhen allow_pickle=False\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mload(fid, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_kwargs)\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot load file containing pickled data when allow_pickle=False"
     ]
    }
   ],
   "source": [
    "np.load('/home/wangyh/uro_biomarker/patho_AI/normed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c7a7fa1-d570-406f-a79a-586a7426f415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d4858cf-5a02-4728-bcf1-de2ce38db5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "377"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir = '/mnt/wangyh/CN_patches'\n",
    "dir_H = os.path.join(dir,'H')\n",
    "dir_L = os.path.join(dir,'L')\n",
    "len(os.listdir(dir_H))+len(os.listdir(dir_L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c01fa4-4721-4726-adfe-89d511086cae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "patho_AI",
   "language": "python",
   "name": "patho_ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4e28155199267a10c509b59e8e194816b4d500ee9999e65bedc01748a29bbc7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
